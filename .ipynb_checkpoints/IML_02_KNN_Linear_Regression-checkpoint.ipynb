{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning \n",
    "## Practical Session 02\n",
    "Sharon Ong, Department of Cognitive Science and Artificial Intelligence – Tilburg University "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mglearn in c:\\users\\20233608\\appdata\\roaming\\python\\python310\\site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (1.25.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (2.0.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (10.0.1)\n",
      "Requirement already satisfied: cycler in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (0.11.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\20233608\\appdata\\roaming\\python\\python310\\site-packages (from mglearn) (2.37.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from mglearn) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from matplotlib->mglearn) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from matplotlib->mglearn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from matplotlib->mglearn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from matplotlib->mglearn) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from matplotlib->mglearn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from matplotlib->mglearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from pandas->mglearn) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from pandas->mglearn) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from scikit-learn->mglearn) (1.11.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from scikit-learn->mglearn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\20233608\\.conda\\envs\\flverstoep\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mglearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# We will need the mglearn package for this practical and following practicals. Uncomment the following line if this package is not installed. \n",
    "!pip install --user mglearn \n",
    "\n",
    "# If the line above does not work, uncomment the lines below instead. \n",
    "#import sys\n",
    "#!{sys.executable} -m pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. K-Nearest Neighbour Classification\n",
    "The k-NN algorithm is arguably the simplest machine learning algorithm. Building the model consists only of storing the training dataset. To make a prediction for a new data point, the algorithm finds the closest data points in the training dataset—its “nearest neighbors.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate the case for nearest-neighbour classification with the \"forge\" dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABolElEQVR4nO3de1xUdf4/8NcwyMAw3CHwAkLKJfKSZqVYYmsxlpppaqkp2GVrU0nNNS1tKy21+oGIZt/aEs02S/D20BSkVTPxggrmegMNAxMvA4IMV2E+vz9YZkW5OzNnZng9H4951MycM+d9OOB5z/t8zvsjE0IIEBEREUnARuoAiIiIqP1iIkJERESSYSJCREREkmEiQkRERJJhIkJERESSYSJCREREkmEiQkRERJJhIkJERESSsZU6gKbodDpcunQJTk5OkMlkUodDRERELSCEQElJCTp16gQbm6ZrHmadiFy6dAm+vr5Sh0FERERtkJeXhy5dujS5jFknIk5OTgBqd8TZ2VniaIiIiKglbty4AV9fX/15vClmnYjUXY5xdnZmIkJERGRhWjKsgoNViYiISDJMRIiIiEgyTESIiIhIMkxEiIiISDJMRIiIiEgyTESIiIhIMkxEiIiISDJMRIiIiEgyTESIiIhIMkxEiIiISDJMRIiIiEgyTESI/is1NRUP9AxFamqq1KEQEbUbTESIAAghsODdd3D8P6ex4N13IISQOiQionaBiQgRgJSUFBw8nI6Z/e1w8HA6UlJSpA6JiKhdYCJC7Z4QAu+/twD9fe3w/yIU6O9rh/ffW8CqCBGRCTARoXavrhry/iBbyGQyvD/IllURIiITYSJC7dqt1ZCIbnIAQEQ3OasiREQmwkSE2rXbqyEAWBUhIjIhJiLUbjVUDanDqggRkWkwEaF2q6FqSB1WRYiITIOJCLVLTVVD6rAqQkRkfExEqF1qqhpSh1URIiLjYyJC7U5LqiF1WBUhIjIuJiLU7rSkGlKHVREiIuOylToAIlOqq4Z0c7eFp1KGY/k1za7jqZShm7st3n9vASIiIppNXoiIqOWYiFC7UlVVhYt5ubhYWI1+X1W3bt2LeaiqqoJCoTBSdERE7Q8TEWpXFAoF0g6l49q1a61e95577mESQkRkYExEqN3x9fWFr6+v1GEQkZVITU3F7JnR+Cx2OZ544gmpw7E4HKxKRETURkIILHj3HRz/z2ksePcd3l3XBkxEiIiI2qjuLryZ/e14d10bMREhIiJqg1t7Ev2/CAV7DrURExEzl5qaigd6hiI1NVXqUOg2PDZE7dvtPYnYc6htZMKMU7cbN27AxcUFxcXFcHZ2ljockxNCIKz/Izh4OB39H34IaQcPsYeFmeCxIWrf6v4NQP5xpE1RQCaT1b62uhLo2Lvd/5vQmvM3KyJmjNcepdNctaO5Y8NqCZF1a6hDM6sibcOKiJm6Pdtmlm06zVU7mjs2rJYQWbeGqiH13uO/16yIWANee5ROc9WO5o4NK1lE1q2p+ar473XrsSJihnjtUTotrXY0dmz2HziIgQP6s5JFZKWaqobUW6ad/+2zImLheO1ROi2tdjR2bBYvXsxKFpEVa8ns3fzbbx1WRMwMrz1Kp7XVjtuPzYBvKnCmyA73ud1kJYvICrWkGlJv2Xb8t8+KiAXjtUfptLbacSuZTIYRgTYo1paykkVkpVpSDanDv/2WY0XEjPDao3Saq0Q1VO24Y/2vS1EjgEOvOLKSRWRl6v6NuHYuAz88p0BL/oyFAJ5PqoRX9z7t7m+/Nedvo86++/777+ODDz6o95q3tzcuX75szM1arLpse+dEZbPXHod+V5tlq9VqE0dpnZr62ddVOw7tLsX7Ixs+Ninna3DwT12j6/OYEVm2qqoqXMzLxcXCavT7qrp1617MQ1VVFRQKhZGis2xGrYi8//77SExMrNfUSS6Xw8vLq0Xrt6eKCK89Sqe5n31T1Q79+9+UAQDSXmo4UeExI7J8eXl5uHbtWqvXu+eee9ClSxcjRGS+zKYiAgC2trbw8fEx9mYsXkuqIXX4DduwmvvZN1Xt0L9/sYaVLCIr5+vrC19fX6nDsDpGT0Sys7PRqVMnKBQKPPLII/j4449x7733NrhsZWUlKisr9c9v3Lhh7PDMQt0Mjt3cbeGplOFYfk2z63gqZejmbov331uAiIgIfsNuo1tnz4zoJm/4/b2V6OYma/DYCCEwZ1cFHuls0+D6t4roJtfPzsljRkRUy6iJyCOPPIK1a9ciKCgIV65cwaJFixAWFoaTJ0/Cw8PjjuUXL158x5iS9oDXHqXTXDWkqga4eEOHizcE+n1V2ujnsJJFRNQ2Jr1rprS0FN26dcOcOXMwa9asO95vqCLi6+tr1DEiqampmD0zGp/FLscTTzxhlG20BK89ml5LR8Ff1upwveK/fyYCmPvzTbj5BuObhDV4eUokSi+dxQ/P2XMUPRHRf5nVGJFbOTo6omfPnsjOzm7wfYVCYdJv9kIILHj3HRz/z2ksePcdDBkyRLITA689mt7dVKJk1wsRFBSEwoICXCysabJa0uC2WckiIgJg4kSksrISp0+fxmOPPWbKzTbq1snJYg9KXy43l+pMe6FQKJB2KL3NlShnZ+e7Wp9JCBGRkS/NzJ49GyNGjICfnx+uXr2KRYsWYe/evThx4gS6du3a7PrGvH23ucnNTI1TxxMRkbUwmxbvFy9exPjx4xEcHIzRo0fDzs4OBw8ebFESYmzNTW4mVTycOp6IiNqTdtnivbnJzUxdjTC36gwREdHdMJuKiLlqbnIzU1cjzK06Q0REZCrtriLS3ORmpq5GmFt1hoiI6G6xItKEpqZxlqIaYW7VGSIiIlNqVxWRlkwsZ8pqhLlVZ4iIiAyBFZFGNFUNqWPKaoS5VWeIiIhMrd0kIs1NbnarWycnM1bBqCXxmCIOIiJqf1JTU/FAz1CkpqZKHUr7SURaUg2pY4pqhLlVZ4iIqH24fXoTqb/ototEpK760M3dVj+Ve3MPT6UM3dxtjVKNMLfqDJEUzOkbGVF7Ym4NNNvFYNXKykp0D+iKi/lXWr2ubycfZP9+waDzgiQnJ2Po0KHYOVEJdffmp/tJPleNod+VYefOnZw6nqwCpzQgkoapGmia7ey7Urnbyc0MmYQ0VJ1pzq3VmYiICP6DTRbP3CacJGov6v72dk5U6i//D/1O2r/BdlERMSfmVp0hMjVOaUAkDVM20GRFxIyZU3WGSArm+I2MqD24/W8PgFn8DbIiQkQmwykNiKRh6gaabGhGRGaJUxoQScOcG2gyEaFW422X1BZN3bbO29SJjMfcG2gyEaFWMbdGOGQ5zPkbGZE1M/cGmhwjQq1S1wOl9rbLKvY2oRYxtwknidqLlvzt1VvWQH+DHCNCRnFree//RShYSqcWM/dvZETWytymN2lwu6yIUEvd3hGWHV+pJaT6RkbU3tX97V07l4EfnlOgJX9OQgDPJ1XCq3ufu/obbM35m4kItQhvu6S24pQGRNKQsoEmG5qRwZlrIxwyb5zSgEg6ltJAkxURalZdNUT35zEcfFlp9EY4dKfU1FTMnhmNz2KX44knnpA6nBbjlAZE7RMvzZBBbdu2DSNGjGi0tM5SunFZ+ky1eXl5bf5G1qVLFyNERETGxkTESIQQKCgogFarhUqlgoeHh0WdENri3LlzCAkKRN+ONjj0iiNvu5QAb5kmIkvD23cNrKioCHFxcQgMDoGXlxcCAgLg5eWFwOAQxMXFoaioSOoQjeL7779HYGAgagSw8HF73nYpAd4yTUTWjhWRZiQnJ2PM2LEoLSuDY9BA2AeFwcZeBV2FFhVZaSjN2g9HpRKJGzZY1bfUF154AT/88APkMqBf5w448FLjiQjAqoix8JZpIrJEvDRjIMnJyRg2fDgU/n3gro6GXOV2xzI12usoTF6OygsZ2L5tm8WfHKqqqu4YHMjbLqXBW6aJyFIxETGAoqIi+Pr5QecdAs9R8yGzaXiiIAAQuhpoNi2CzZUzyMvNhaurq+kCNaCcnBzce++9AAAPDw8EdgvAtXOZJm+EQ7Ua67/BhI+IzB37iBjAmjVrUFpWhs7q6CaTEACQ2cjhpp6O/C+mYO3atYiOjjZRlIbz448/4vnnnwcAzJo1Cx9//HHtbZeF1ej3VXWrPqvqYl6DlRVquZbOVMs+G0Rk6VgRaYAQAoHBIbhs6wPPZ+a0eD3N1qXwqb6C7LNnLOrk8OKLL+K7774DUPstPCIiAgBvu5RSc91IWRUhInPGSzN3SaPRwMvLC54j58Ix5NEWr1d6eh80W5dCo9HAw8PDiBEaxs2bN2FnZ6d/np+fDx8fHwkjIoAz1RKR5ePtu3dJq9UCAGzsVa1ar275kpISg8dkaBcuXNAnIW5ubqiurmYSYiY4Uy0RtSdMRBqgUtUmFLoKbavWq1veycnJ4DEZUlJSEgICAgAA0dHRKCwshFze9DgYMo2mxobc7taxImZc2CQiahITkQZ4eHigW2AQKrLSWrVeeXYaugUGwd3d3UiR3b3IyEiMGTMGALBjxw7ExcVJHBHdqiXVkDqsihCRNeBdMw2QyWSYPvUNzHzrLbhqrzfYP+R21dpClGelITomxiyv198+HuTSpUvo2LGjhBHR7ThTLRG1Rxys2ojW9hEp2LQIMjPtI5Kbm4uuXbsCqL1sdP36dV6KMUOcqZaIrAX7iBiAq6srEjdswLDhw6HZtAhu6umwVd15yaVaW4jryfGovJCBn7ZvN7skZNOmTRg9ejQAYNq0aYiPj5c4ImqMQqFA2qH0Ft8yvW/fPsyYMaP2/9MOMgkhIovEikgz6uaaKSsrg0NQGBwC/zfXTNnZX1GefRCOjkokJSbq+2+Yi5dffhnffPMNAGDbtm0YNmyYxBGRoU2ePBnffvstOnfujIsXL0odDhERAPYRMbiioiKsXbsWy1esxPnsrP+9IbPBPV6eyMrKgouLi2Tx3a66uhodOnTQP7948SI6d+4sYURkTHXjQj766CO88847EkdDRMRExGiEECgsLERJSQmcnJzg6empf91c5OXlwc/PDwDg4OCAkpISjgexcmVlZXB0dAQAZGRk4IEHHpA2ICJq99jQzEhkMhk8PDzg7+8PDw8P9OvXDwBw6tQpiSOrtXXrVn0S8vrrr6OsrIxJSDugVCpx9OhRAECfPn1QXl4ucURERC3HROQufPXVVwCA1157TeJIgL/+9a8YOXIkgNqEZNWqVRJHRKbUt29ffPjhhwBqExMiIkthskRk8eLFkMlk+lH+1qCuBP7rr79KFkN1dTXs7Oz0SVFeXh5GjBghWTwknQULFuCee+4BAEyZMkXiaIiIWsYkiUh6ejq+/PJL9OrVyxSbMyl/f38Atb06TO3ixYvo0KEDbt68qf8vZ71t3y5dugQASEhIwM6dOyWOhoioeUZPRLRaLSZOnIivvvoKbm7Ndyi1NGvWrAFQO2eLKW3btg2+vr4AgFdffRVVVVWwtWVbmPZOLpfjjz/+AAA89dRTKCgokDgiIqKmGT0RmTp1KoYNG4Ynnnii2WUrKytx48aNeg9z99hjjwEAtmzZYrJtvvHGG/rLL5s3b8aXX35psm2T+fPz88PatWsBAJ6enmZ1VxcR0e2MmoisX78ex44dw+LFi1u0/OLFi+Hi4qJ/1H3jN2cymUx/a5JGozHqtmpqauDg4KAfiJqbm6sfoEp0q0mTJuHxxx8HAAwYMEDiaIiIGme0RCQvLw9vvvkm1q1bB3t7+xatM2/ePBQXF+sfeXl5xgrPoOq+fc6dO9do27h06RJsbW1RUVEBmUyGmzdvWkSiRtL5+eefAQCHDh3SD2YmIjI3RmtotnnzZowaNapeH4uamhrIZDLY2NigsrKy2R4X5tbQrDFCCNjY2Oj/39B++uknfXv2KVOm6Nu2EzWnqKhIPzbr3Llz6Natm8QREVF7YBYNzYYMGYITJ04gMzNT/+jXrx8mTpyIzMxMq2q0devU61qt1qCfPX36dH0SkpSUxCSEWsXV1RX//ve/AQDdu3dHdXW1xBEREdVntETEyckJPXr0qPdwdHSEh4cHevToYazNSubrr78GACxcuNAgn1dTUwNnZ2esWLECAHDhwgX9LLpErfH444/jjTfeAACrvHONiCwbO6saSGRkJADgk08+uevPys/Ph62tLUpKSgAAVVVV6Nq1611/LrVfK1euBFBbsePEeERkTkyaiOzZswfLli0z5SZN5tZLTZWVlW3+nOTkZHTq1AlA7Z0PQoh6M+kStVVFRQWA2rvTDh48KHE0RES1WBExoM8++wwAEBcX16b1Z86ciaFDhwIANmzYoL8bh8gQFAoFTp48CaD2ll5Dj2ciImoLo901YwiWctdMnaqqKigUCgCtu3umpqYGnp6eKCoqAgDk5OToW8cTGVpsbCxmzZoFANDpdPUGWxMRGYJZ3DXTHtnZ2en/v6V3J1y5cgW2trb6JKSqqopJCBnVzJkzERQUBAAYM2aMxNEQUXvHRMTA6pqa1c1B05Rdu3bBx8cHADBhwgSOByGTOX36NABg48aN2LRpk8TREFF7xkTEwN59910AwCuvvIK0tDQMGPgo0tLS7lhu9uzZiIiIAFDbCv+7774zaZzUvtnY2Ohn6h09ejQuX74scURE1F5xulYDU6lU+v9fHh+Pg2n7sWLFSoSFhQGovSbv4+ODa9euAQDOnz+Pe++9V5JYqX3r2LEjkpKS8Nxzz6Fjx46oqanRdwgmIjIV/qtjBK+88goAIDExEbbuXZCYmAiNRoOrV69CLpfrk5DKykomISSp0aNH49lnnwUAq2w0SETmj4mIESxZsgQAUKMTuGf0u6gRAgsWLIC3tzcAYNy4cRBC1BvcSiSVjRs3AqgdN9LWW8+JiNqKl2YM4M8//8SVK1fqvyiTQxk8EB08fOHQfQC++L8vAQAfffQRhg4dimPHjsHb2xudO3eWIGKi/5HJZCgpKYGTkxNmzJiBJ598EqGhoVKHRUTtBPuIGMCgx/+CfXt2139RZgPvCUtg3yUUFRdP4sp3cwGIO9bb+++fTRcoURMOHDigH8tUWVnJih0RtVlrzt+siBjAK1OikH7oEG4KGVyfeB0dPHxhY69CB9faW3Ptu9yPTq99BV2FFjcL8lCU+gU6yARejoqUOHKi/xkwYADefvttLF26FAqFolVN+YiI2opjRAxg8uTJOHokHd39/VCUshI3NX/ok5A6HVx9cPPaHyhKWYnAgK44eiQdkydPlihiooYtWbIESqUSADB9+nSJoyGi9oCJiIGEhobi6JF0jBn1LAq2x6JaW1jv/WptIQp+isXY0aNw9Eg6r8GT2SouLgYArFixAnv27JE2GCKyekxEDMjR0RHh4YMgk8sht6/tJ6KrLAMAyO1VkMnlCA8fpP/GSWSObG1tkZ2dDQB4/PHH9dMPEBEZAxMRAzt69Cgc7vGH0OlQ8NMy5C0bh4KflkEIHey9uuLo0aNSh0jUrO7du+PLL2vv9HJzc+N4ESIyGiYiBnbo8BHUyO1x7bu3UH0uDTNnzkT1uTRcWzcbOlt7HDyULnWIRC3y6quv4uGHHwYA/XQERESGxkTEgCoqKnD69ElUXjwJfw9HHD2SjpiYGBw9ko6u7g6ovHgKp0+fREVFhdShErXIwYMHAQCpqamcD4mIjIKJiAGVl5ejZ68HMGXKlHoDUusGskZFRaFX7z5MRMhiyGQy/ZQEL774InJzcyWOiIisDRuaGZhOp2ty4rDm3icyRzt27MDTTz8NAKiuroZcLpc4IiIyZ605f/OMaGDNJRlMQsgSPfXUU4iMrG3A5+fnJ3E0RGRNeFYkohZJSEgAAFy6dAkfffSRtMEQkdVgIkJELVZWVtsXZ/78+cjIyJA4GiKyBkxEiKjFHBwccOzYMQBA3759UV5eLnFERGTpmIgQUav06dMHixYtAgB2CSaiu8ZEhIha7d1330WnTp0AAFFRUdIGQ0QWjYkIEbVJXU+RNWvWYMeOHRJHQ0SWiokIEbWJXC7HH3/8AQB4+umnodFoJI6IiCwRExEiajM/Pz+sW7cOAODl5cXJ8Yio1ZiIENFdmThxIp544gkAQP/+/SWOhogsDRMRIrprKSkpAIDDhw/jyy+/1L+elpaGQQP7Iy0tTarQiMjMMREhorsmk8lQVFQEAHjttddw7tw5AMCK+HjsSzuElStWSBgdEZkzJiJEZBAuLi7Ys2cPACAwMBD5+flISkpEsIcNEhM3cDArETXIVuoAiMh6hIeHY/r06YiPj4e/vz8gdNj8ggN6/1851q5di1mzZkkdYrsghEB1dTVqamqkDoWsWIcOHQwyE7dMmPEw99ZMI0xE0vnzzz9x5coV/fMHH3wQtjbAmNAO+P45B4xPKsexCl98/8OGeut5e3ujc+fOpg7XqlVVVSE/P18/LxCRschkMnTp0gUqleqO91pz/mZFhIjuWuSL4/Hznn31XtMJYNpDHQAAUx/qgPCEHDz44IP1lnni8UHY9e+9JovT2ul0OuTk5EAul6NTp06ws7ODTCaTOiyyQkIIXLt2DRcvXkRgYOBdVUaYiBDRXZs85RUcOJSODqIKK56yQ6iXHG72MgS41Q5De9TPFuemO+J6hcCpazWYtqMKN2V2mBT1ssSRW5eqqirodDr4+vpyHiAyOi8vL1y4cAE3b968q0SEg1WJ6K5NnjwZ6UeOorN/d7y2/Sb+c7VGn4TUCXCzwYkrNXht+010CQhE+pGjmDx5skQRWzcbm7v/p10IAY1GgwsXLkCj0bBZHd3BUNU2JiJEZBChoaE4fOQYnhk1BpGbK5Bfoqv3fn6JDlFbKjBy9FgcPnIMoaGhEkVKTSkqKkJcXBwCg0Pg5eWFgIAAeHl5ITA4BHFxcfrbtIkMhYkIERmMo6MjBoWHw1Yug5tD7belksrab9JuDjLIZUDvBx7gZQMzlZycDF8/P8x86y1csfWB58i5uOf5RfAcORdXbH0w86234Ovnh+TkZKlDbZa/vz+WLVvW4uX37NlTrx+OVAYPHowZM2ZIGoOpMREhIoM6evQoenjboUYHTNlSAeclJXhpSwV0Agj2tMHcuXNx9epVqcOk2yQnJ2PY8OHQeYeg8+sJ8HhmDhxDHoWD/wNwDHkUHs/MQefXE6DzDsGw4cMNnowY+gScnp6Ov/71ry1ePiwsDPn5+XBxcTFYDJYoKSkJoaGhUCgUCA0NxaZNm4y+TSYiRGRQRw8fhJNtNR7+phI/nrXBzJkz8cNZGzz8dSXcHWSwtam9bbegoEDqUOm/ioqKMGbsWCj8+8Bz1HzIVW4NLidXucFz1Hwo/PtgzNixJq8e1PVHaQkvL69WVd7s7Ozg4+PTru8yOnDgAJ5//nlMmjQJx48fx6RJkzBu3DgcOnTIqNtlIkJEBlNRUYH/nD6Dfbk1kLkHIP3IUcTExCD9yFEIN3/8mlsDgdp/6D09PSUvg1OtNWvWoLSsDO7qaMhsmr77QWYjh5t6OsrKyrB27VqDbD8qKgp79+5FXFwcZDIZZDIZLly4oL9ckpycjH79+kGhUGDfvn04f/48Ro4cCW9vb6hUKjz00ENITU2t95m3X5qRyWT45z//iVGjRkGpVCIwMBBbt27Vv3/7pZmEhAS4uroiOTkZ9913H1QqFYYOHYr8/Hz9OtXV1YiOjoarqys8PDzw9ttvIzIyEs8++2yT+7t//36Eh4dDqVTCzc0NarUa169fb3DZdevWoV+/fnBycoKPjw8mTJhQr6J4/fp1TJw4EV5eXnBwcEBgYCBWr14NoPYuqmnTpqFjx46wt7eHv78/Fi9e3Ghcy5Ytw5NPPol58+YhJCQE8+bNw5AhQ1p1iastjJqIrFq1Cr169YKzszOcnZ0xYMAA7Nixw5ibJCIJlZeXo2+vHnhpypR6A1LrBrJOiYpCvz699R1W3dzcUFJSImXI7Z4QAvErP4cyaGCjlZDb2arc4RAUhuUrVhrkbpq4uDgMGDAAr776KvLz85Gfnw9fX1/9+3PmzMHixYtx+vRp9OrVC1qtFk8//TRSU1ORkZEBtVqNESNGIDc3t8ntfPDBBxg3bhx+++03PP3005g4cSIKCwsbXb6srAyfffYZvv32W/zyyy/Izc3F7Nmz9e8vXboU3333HVavXo39+/fjxo0b2Lx5c5MxZGZmYsiQIbj//vtx4MAB/PrrrxgxYkSjXXCrqqqwcOFCHD9+HJs3b0ZOTg6ioqL07y9YsACnTp3Cjh07cPr0aaxatQqenp4AgOXLl2Pr1q348ccfcfbsWaxbt66243EjDhw4gIiIiHqvqdVqo09aadQ+Il26dMGSJUvQvXt3ALVZ98iRI5GRkYH777/fmJsmIgm4ubnhQPqxBm8fdXR0xDerV0On08HGxgZCCMTGxsLZ2RmlpaUcwCqRgoICnM/OgufI0a1azyEwDOe3LkVhYSE8PDzuKgYXFxfY2dlBqVTCx8fnjvc//PBDPPnkk/rnHh4e6N27t/75okWLsGnTJmzduhXTpk1rdDtRUVEYP348AODjjz9GfHw8Dh8+jKFDhza4/M2bN/HFF1+gW7duAIBp06bhww8/1L8fHx+PefPmYdSoUQCAFStW4KeffmpyXz/55BP069cPn3/+uf61ps6HL730kv7/7733XixfvhwPP/wwtFotVCoVcnNz0adPH/Tr1w8A6iUaubm5CAwMxKOPPgqZTIauXbs2Gdvly5fh7e1d7zVvb29cvny5yfXullErIiNGjMDTTz+NoKAgBAUF4aOPPoJKpcLBgweNuVkiklBzPSzq3o+JicHrr78OoDZJKS8vN3psdCetVgsAsLG/s013U+qWN0VFq+4kW6e0tBRz5sxBaGgoXF1doVKpcObMmWYrIr169dL/v6OjI5ycnJocOK1UKvVJCAB07NhRv3xxcTGuXLmChx9+WP++XC6/o3vw7eoqIi2VkZGBkSNHomvXrnBycsLgwYMBQL+vf/vb37B+/Xo88MADmDNnTr3qRVRUFDIzMxEcHIzo6GikpKQ0u73bx8gIIYw+bsZkY0Rqamqwfv16lJaWYsCAAQ0uU1lZiRs3btR7EJH1WrVqFSIjIwHU/qNfWVkpcUTtT908IboKbavWq1veycnJ4DHdztHRsd7zv//970hKSsJHH32Effv2ITMzEz179kRVVVWTn9OhQ4d6z2UyGXQ6XSNLN7z87ZeiGjpxN8XBwaHJ929VWlqKiIgIqFQqrFu3Dunp6fq7WOr29amnnsIff/yBGTNm4NKlSxgyZIj+8lHfvn2Rk5ODhQsXory8HOPGjcOYMWMa3Z6Pj88d1Y+rV6/eUSUxNKMnIidOnIBKpYJCocDrr7+OTZs2NdrIaPHixXBxcdE/br1GSETWKSEhAWPHjgUA2Nvb4+bNmxJH1L54eHigW2AQKrJaNw6gPDsN3QKD4O7ubpA47OzsWjxb8L59+xAVFYVRo0ahZ8+e8PHxwYULFwwSR0u5uLjA29sbhw8f1r9WU1ODjIyMJtfr1asXfv755xZt48yZM9BoNFiyZAkee+wxhISENFjB8fLyQlRUFNatW4dly5bhyy+/1L/n7OyM559/Hl999RV++OEHJCUlNTouZsCAAdi1a1e911JSUhAWFtaieNvK6IlIcHAwMjMzcfDgQfztb39DZGQkTp061eCy8+bNQ3Fxsf6Rl5dn7PCIyAz8+OOPGDZsGIDaE1JLb9GkuyeTyTB96hsozdqPGm3Dd27crlpbiPKsNERPm2qwsr2/vz8OHTqkbynfVKWie/fu2LhxIzIzM3H8+HFMmDChyeWNZfr06Vi8eDG2bNmCs2fP4s0338T169eb/JnMmzcP6enpeOONN/Dbb7/hzJkzWLVqFTQazR3L+vn5wc7ODvHx8fj999+xdetWLFy4sN4y7733HrZs2YJz587h5MmT2LZtG+677z4AQGxsLNavX48zZ84gKysLGzZsgI+PD1xdXRuM7c0330RKSgqWLl2KM2fOYOnSpUhNTTV6gzWjJyJ2dnbo3r07+vXrh8WLF6N3796Ii4trcFmFQqG/w6buQUTtw7Zt2/D4448DqC2Jt/TbMd29yMhIOCqVKExeDqFr+ucudDUoSo6HUqk06FxBs2fPhlwuR2hoKLy8vJoc7xEbGws3NzeEhYVhxIgRUKvV6Nu3r8Fiaam3334b48ePx+TJkzFgwACoVCqo1WrY29s3uk5QUBBSUlJw/PhxPPzwwxgwYAC2bNkCW9s77x3x8vJCQkICNmzYgNDQUCxZsgSfffZZvWXs7Owwb9489OrVC4MGDYJcLsf69esB1F52W7p0Kfr164eHHnoIFy5cwE8//dToOK6wsDCsX78eq1evRq9evZCQkIAffvgBjzzyyF38lJonEyaeyWjIkCHw9fVFQkJCs8veuHEDLi4uKC4uZlJC1E488sgj+nJ3TU2NQSZway8qKiqQk5ODgICAJk+GDanrrKrw7wM39XTYqu685FKtLcT15HhUXsjAT9u333GrZ3un0+lw3333Ydy4cXdULqxRU79vrTl/G/X23XfeeQdPPfUUfH19UVJSgvXr12PPnj3YuXOnMTdLRBbs0KFD6NGjB06ePAm5XA6dTteuu12ailqtxvZt2zBm7FjkfzEFDkFhcAgMg429CroKLcqz01CelQalUskk5L/++OMPpKSkIDw8HJWVlVixYgVycnIwYcIEqUOzKEZNRK5cuYJJkybp+/f36tULO3furHc/OBHR7f7zn/8gICAAFy5cgI2NDZMRE1Gr1cjLzcXatWuxfMVKnN+6VP9et8AgRMfEIDIyst3Px1LHxsYGCQkJmD17NoQQ6NGjB1JTU/VjNKhlTH5ppjV4aYao/RJCwNvbG9euXYOtrS2qqqqYjDTjbi7N3E4IgcLCQpSUlMDJyQnu7u78+VM9FnFphoiorWQyGa5cuQKVSoWysjK4ubk1e0cCGY5MJoOHh8ddd00lag5HgRGR2ZLJZPrOn8XFxewtRGSFmIgQkVm7tfvln3/+ieDgYIkjIiJDYiJCRGZPJpPp+4pkZWVJ0jOCiIyDiQgRWQQbGxt9MpKRkYHHHntM4oiIyBCYiBCRxbCxsdG3f//111+hVqsljsi6paam4oGeoUhNTZU6FLJiTESIyKLI5XL9xHgpKSkYNWqUxBFZJyEEFrz7Do7/5zQWvPtOs7PKmht/f38sW7asxcvv2bMHMpkMRUVFRoupJQYPHmz0uV3MDRMRIrI4tra2qKysBABs3rwZEydOlDgi65OSkoKDh9Mxs78dDh5OR0pKilG3Z+gTcHp6Ov7617+2ePmwsDB988326uTJk3juuefg7+8PmUzWqkTubjARISKLZGdnh4qKCgDAv/71L7zyyisSR2Q9hBB4/70F6O9rh/8XoUB/Xzu8/94CyasiQogWz8zs5eUFpVLZ4s+2s7ODj49Pu+5TU1ZWhnvvvRdLliyBj4+PybbLRISILJZCoUBZWRkA4Ouvv0Z0dLTEEVmHumrI+4NsIZPJ8P4gW6NWRaKiorB3717ExcVBJpNBJpPhwoUL+sslycnJ6NevHxQKBfbt24fz589j5MiR8Pb2hkqlwkMPPXTHOJbbL83IZDL885//xKhRo6BUKhEYGIitW7fq37/90kxCQgJcXV2RnJyM++67DyqVCkOHDkV+fr5+nerqakRHR8PV1RUeHh54++23ERkZiWeffbbJ/d2/fz/Cw8OhVCrh5uYGtVqN69evN7jsunXr0K9fPzg5OcHHxwcTJkzA1atX9e9fv34dEydOhJeXFxwcHBAYGIjVq1cDAKqqqjBt2jR07NgR9vb28Pf3x+LFixuN66GHHsKnn36KF154AQqFosl9MCQmIkRk0RwcHFBSUgIAiI+Px5w5cySOyLLdWg2J6CYHAER0kxu1KhIXF4cBAwbg1VdfRX5+PvLz8+s1r5szZw4WL16M06dPo1evXtBqtXj66aeRmpqKjIwMqNVqjBgxArm5uU1u54MPPsC4cePw22+/4emnn8bEiRNRWFjY6PJlZWX47LPP8O233+KXX35Bbm4uZs+erX9/6dKl+O6777B69Wrs378fN27cwObNm5uMITMzE0OGDMH999+PAwcO4Ndff8WIESP0d4TdrqqqCgsXLsTx48exefNm5OTkICoqSv/+ggULcOrUKezYsQOnT5/GqlWr4OnpCQBYvnw5tm7dih9//BFnz57FunXr4O/v32R8khBmrLi4WAAQxcXFUodCRGau7t8LAOK9996TOhxJlJeXi1OnTony8vI2f8bOnTsFALFzolKIfzjrHzsnKmtf37nTgBH/T3h4uHjzzTfrvbZ7924BQGzevLnZ9UNDQ0V8fLz+edeuXUVsbKz+OQAxf/58/XOtVitkMpnYsWNHvW1dv35dCCHE6tWrBQBx7tw5/TorV64U3t7e+ufe3t7i008/1T+vrq4Wfn5+YuTIkY3GOX78eDFw4MBG32/o53Crw4cPCwCipKRECCHEiBEjxJQpUxpcdvr06eIvf/mL0Ol0jX5eY27/+TWkqd+31py/WREhgxBCQKPR4MKFC9BoNJJfS6b2x9nZWf/t9sMPP2yyBE0NEw1UQ+oYuyrSlH79+tV7Xlpaijlz5iA0NBSurq5QqVQ4c+ZMsxWRXr166f/f0dERTk5O9S5z3E6pVKJbt2765x07dtQvX1xcjCtXruDhhx/Wvy+Xy/Hggw82GUNdRaSlMjIyMHLkSHTt2hVOTk4YPHgwAOj39W9/+xvWr1+PBx54AHPmzEFaWpp+3aioKGRmZiI4OBjR0dFGH3DcVkxE6K4UFRUhLi4OgcEh8PLyQkBAALy8vBAYHIK4uDjJb4Wj9sXNzQ3Xrl0DALzzzjuIjY2VOCLLcvvYkFuZYqxIYxwdHes9//vf/46kpCR89NFH2LdvHzIzM9GzZ09UVVU1+TkdOnSo9/zW6QNauvztSdjtP6fmkjQHB4cm379VaWkpIiIioFKpsG7dOqSnp2PTpk0AoN/Xp556Cn/88QdmzJiBS5cuYciQIfrLR3379kVOTg4WLlyI8vJyjBs3DmPGjGnx9k2FiQi1WXJyMnz9/DDzrbdwxdYHniPn4p7nF8Fz5FxcsfXBzLfegq+fH5KTk6UOldoRT09P/YDCWbNm4fPPP5c4IsvQVDWkjjGrInZ2do2Ok7jdvn37EBUVhVGjRqFnz57w8fHBhQsXDBpPc1xcXODt7Y3Dhw/rX6upqUFGRkaT6/Xq1Qs///xzi7Zx5swZaDQaLFmyBI899hhCQkIarOB4eXkhKioK69atw7Jly/Dll1/q33N2dsbzzz+Pr776Cj/88AOSkpKaHBcjBSYi1CbJyckYNnw4dN4h6Px6AjyemQPHkEfh4P8AHEMehcczc9D59QTovEMwbPhwJiNkUj4+Prh48SIAYOrUqfjmm2/uWIZdQ+trqhpSx5hVEX9/fxw6dEh/ebepSkX37t2xceNGZGZm4vjx45gwYUKTyxvL9OnTsXjxYmzZsgVnz57Fm2++ievXrzd5C/C8efOQnp6ON954A7/99hvOnDmDVatWQaPR3LGsn58f7OzsEB8fj99//x1bt27FwoUL6y3z3nvvYcuWLTh37hxOnjyJbdu24b777gMAxMbGYv369Thz5gyysrKwYcMG+Pj4wNXVtcHYqqqqkJmZiczMTFRVVeHPP/9EZmYmzp071/YfUgswEaFWKyoqwpixY6Hw7wPPUfMhV7k1uJxc5QbPUfOh8O+DMWPH8jINmVTnzp3135JffvllfPfdd/r3hIV3DTW0llRD6hirKjJ79mzI5XKEhobCy8uryfEesbGxcHNzQ1hYGEaMGAG1Wi3JRIhvv/02xo8fj8mTJ2PAgAFQqVRQq9Wwt7dvdJ2goCCkpKTg+PHjePjhhzFgwABs2bIFtra2dyzr5eWFhIQEbNiwAaGhoViyZAk+++yzesvY2dlh3rx56NWrFwYNGgS5XI7169cDAFQqFZYuXYp+/frhoYcewoULF/DTTz/BxqbhU/+lS5fQp08f9OnTB/n5+fjss8/Qp08fo/fokQkz/gu8ceMGXFxcUFxcDGdnZ6nDof+Ki4vDzLfeQufXExpNQm5VrS1E/hdTEBsTwz4PZHLnz59H9+7dAQAbNmzAmDFjkJycjKFDh2JmfzvEHqzCzp07rWLemoqKCuTk5CAgIKDJk+Ht6n4eOycqoe5+5wnxjuXPVWPod2VW83MzFJ1Oh/vuuw/jxo27o3JhjZr6fWvN+ZuJCLWKEAKBwSG4bOsDz2da3q9Bs3UpfKqvIPvsmXbduZCkcebMGX25esuWLVj80SIg/zjSpigQtroS6NgbaQcPWfzvZlsSESEEwvo/gmvnMvDDcwq05EcgBPB8UiW8uvexip9bW/3xxx9ISUlBeHg4KisrsWLFCqxevRrHjx/X/75ZM0MlIs2nvkS3KCgowPnsLHiOHN2q9RwCw3B+61IUFhbCw8PDSNERNSwkJAS//fYbevXqhZEjRwIAdk5U6sc8DP2udsxDe/x2X1VVhYt5ubhYWI1+X7Wsfbp+3Yt5qKqqMmkXTnNiY2ODhIQEzJ49G0II9OjRA6mpqe0iCTEkJiLUKlqtFgBgY69q1Xp1y5eUlDARIUn07NkTR44cwSMP9UPfjjYNdg2NiIhod9/uFQoF0g6l6297bo177rmn3SYhAODr64v9+/dLHYbFYyJCraJS1SYUugptq9arW97JycngMRG1lEajQY0AFj5ur084WBWpPaHe2lKdyJR41wy1ioeHB7oFBqEiK635hW9Rnp2GboFBcHd3N1JkRE0z166hRO0dExFqFZlMhulT30Bp1n7UaBueLfJ21dpClGelIXra1HZX9ibzYa5dQ4naOyYi1GqRkZFwVCpRmLwcQtd0J0Shq0FRcjyUSiUmT55sogiJ6pO6aygRNY6JCLWaq6srEjdsQOWFDGg2LUK1tuF2wdXaQmg2LULFhQwkJSY22s2PyNik7hpKRI1jIkJtolarsX3bNthcOYP8L6ZAs3UpSk/vQ3lOBkpP74Nm61LkfzEFNlfO4Kft2xERESF1yNROmUPXUEuVlpaGAQMfrTejK5GhMRGhNlOr1cjLzUVsTAx8qq9As3Uprv64QN+8LDYmBhfz8piEkKRaUg2pw6pIffHxK3AwbT9WrFgpdShWxd/fH8uWLZM6DLPBRITuiqurK6Kjo5F9tnaWyJycHGg0GmSfPYPo6Gi4uLhIHSK1Y3XVkG7utvBUynAsv6bZh6dShm7utu2+KqLRaJCUlARb9y5ITExscFI2Qxo8eDBmzJhh0M+MiorCs88+a9DPNJWkpCSEhoZCoVAgNDQUmzZtkjoko2EfETIImUwGDw8PNisjs8KuoW23Zs0a1AgBn9Hv4nJCNNauXYtZs2ZJHZbZqKqqgp2dnVE++8CBA3j++eexcOFCjBo1Cps2bcK4cePw66+/4pFHHjHKNqXERISIrBa7hrbMn3/+iStXrtR77fMv/g8OQWHo4OELh8ABWLnqCwwePLjeMt7e3ujcufNdbz8qKgp79+7F3r17ERcXBwDIycmBv78/Tp06hdmzZ+OXX36Bo6MjIiIiEBsbC09PTwBAYmIiPvjgA5w7dw5KpRJ9+vTBli1b8Omnn2LNmjUAoL8kt3v37jv2AaitxvTo0QMAsG7dOsjlcvztb3/DwoUL9ev6+/vjlVdewblz57Bp0yY8++yzWLNmDdLS0jB37lykp6fD09MTo0aNwuLFi+Ho6AgAuHr1Kl5++WWkpqbCx8cHixYtavbnsWzZMjz55JOYN28eAGDevHnYu3cvli1bhu+///4uftJmSpix4uJiAUAUFxdLHQoRkdkrLy8Xp06dEuXl5a1a77HBjwsA9R4yG7nwnviJ6Pr2NuE9camQyWzuWGbQ438xSNxFRUViwIAB4tVXXxX5+fkiPz9fVFdXi0uXLglPT08xb948cfr0aXHs2DHx5JNPiscff1wIIcSlS5eEra2tiImJETk5OeK3334TK1euFCUlJaKkpESMGzdODB06VP+ZlZWVDW4/PDxcqFQq8eabb4ozZ86IdevWCaVSKb788kv9Ml27dhXOzs7i008/FdnZ2SI7O1v89ttvQqVSidjYWJGVlSX2798v+vTpI6KiovTrPfXUU6JHjx4iLS1NHDlyRISFhQkHBwcRGxvb6M/D19dXxMTE1HstJiZG+Pn53cVP2fCa+n1rzfmbFREionbulSlRSD90CDeFDK5PvI4OHr6wsVehg6sPAMC+y/3o+NcvoavQ4mZBHopSv0AHmcDLUZEG2b6Liwvs7OygVCrh4+Ojf33VqlXo27cvPv74Y/1r33zzDXx9fZGVlQWtVovq6mqMHj0aXbt2BVA7p1AdBwcHVFZW1vvMxvj6+iI2NhYymQzBwcE4ceIEYmNj8eqrr+qX+ctf/oLZs2frn0+ePBkTJkzQj20JDAzE8uXLER4ejlWrViE3Nxc7duzAwYMH9ZdUvv7662Ynxbt8+TK8vb3rvebt7Y3Lly83ux+WiINViYjaucmTJ+PokXR09/dDUcpK3NT8oU9C6nRw9cHNa3+gKGUlAgO64uiRdKM3KTx69Ch2794NlUqlf4SEhAAAzp8/j969e2PIkCHo2bMnxo4di6+++grXr7es4/Pt+vfvX++uqgEDBiA7Oxs1Nf9r2tivX7874ktISKgXn1qthk6nQ05ODk6fPg1bW9t664WEhLSop9Ltd3gJIay2MzUTESIiQmhoKI4eSceYUc+iYHvsHY0Kq7WFKPgpFmNHj8LRI+kIDQ01ekw6nQ4jRoxAZmZmvUd2djYGDRoEuVyOXbt2YceOHQgNDUV8fDyCg4ORk5NjlHjqxn3cGt9rr71WL7bjx48jOzsb3bp109911doEwsfH547qx9WrV++oklgLJiJERASg9kQbHj4IMrkccvv/zrRdWQYAkNurIJPLER4+CEql0uDbtrOzq1d9AIC+ffvi5MmT8Pf3R/fu3es96pICmUyGgQMH4oMPPkBGRgbs7Oz0t7o29JmNOXjw4B3PAwMDIZc33gSvLr7bY+vevTvs7Oxw3333obq6GkeOHNGvc/bsWRQVFTUZy4ABA7Br1656r6WkpCAsLKxF+2JpmIgQEZHe0aNH4XCPP4ROh4KfliFv2TgU/LQMQuhg79UVR48eNcp2/f39cejQIVy4cAEajQY6nQ5Tp05FYWEhxo8fj8OHD+P3339HSkoKXnrpJdTU1ODQoUP4+OOPceTIEeTm5mLjxo24du2afgyGv78/fvvtN5w9exYajQY3b95sdPt5eXmYNWsWzp49i++//x7x8fF48803m4z57bffxoEDBzB16lR9pWbr1q2YPn06ACA4OBhDhw7Fq6++ikOHDuHo0aN45ZVX4ODg0OTnvvnmm0hJScHSpUtx5swZLF26FKmpqQbvs2I2DD+O1nB41wwRUcu19a6ZW/Xo2Vsoutwv7O/pKuwdlGLmzJnC3kEp7O/xF4ouoaJHz96GC/gWZ8+eFf379xcODg4CgMjJyRFCCJGVlSVGjRolXF1dhYODgwgJCREzZswQOp1OnDp1SqjVauHl5SUUCoUICgoS8fHx+s+8evWqePLJJ4VKpRIAxO7duxvcdnh4uHjjjTfE66+/LpydnYWbm5uYO3eu0Ol0+mW6du3a4J0uhw8f1m/D0dFR9OrVS3z00Uf69/Pz88WwYcOEQqEQfn5+Yu3atY1+1q02bNgggoODRYcOHURISIhISkpq8c/SVAx114xMCPNtHXjjxg24uLiguLgYzs7OUodDRGTWKioqkJOTg4CAANjb27dpfZWTE2qqqxFyXyiSEjcgNDQUp06dwujnxuDsmdOQ29pCW1LSps83V4MHD8YDDzzAtuut1NTvW2vO37x9l4iIAADl5eXo2esB9OndEytWrNCPBakbyDpt2jQcP3ESFRUVVpWIkLSYiBAREQDAzc0NR9MPwcbmzuGDjo6OWL16NXQ6XYPvE7UVExEiItJrLsmwxiRkz549UofQrhn1N2rx4sV46KGH4OTkhHvuuQfPPvsszp49a8xNElklIQQ0Go3+jgIzHtpFRNQqRk1E9u7di6lTp+LgwYPYtWsXqqurERERgdLSUmNulshqFBUVIS4uDoHBIfDy8kJAQAC8vLwQGByCuLi4ZvsREBGZO5PeNXPt2jXcc8892Lt3LwYNGtTs8rxrhtqz5ORkjBk7FqVlZXAMGgj7oDDY2Kugq9CiIisNpVn74ahUInHDBqjVaqnDJTNwt3fNELWGRd41U1xcDABwd3dv8P3KykpUVlbqn9+4ccMkcRGZm+TkZAwbPhwK/z7orI6GXOVW733HkEfhqr2OwuTlGDZ8OLZv28ZkhIgskslGHQkhMGvWLDz66KPo0aNHg8ssXrwYLi4u+oevr6+pwiMyG0VFRRgzdiwU/n3gOWr+HUlIHbnKDZ6j5kPh3wdjxo7lZRoiskgmS0SmTZuG3377Dd9//32jy8ybNw/FxcX6R15enqnCIzIba9asQWlZGdzV0ZDZND7PBQDIbORwU09HWVkZ1q5da6IIqb1IS0vDoIH9kZaWJnUoZMVMkohMnz4dW7duxe7du9GlS5dGl1MoFHB2dq73IGpPhBCIX/k5lEEDG62E3M5W5Q6HoDAsX7GSd9OQQa2Ij8e+tENYuWKF1KFYFX9/f3ZxvYVRExEhBKZNm4aNGzfi3//+NwICAoy5OSKLV1BQgPPZWXAIat0smw6BYTifnYXCwsLmFyZqAY1Gg6SkRAR72CAxcQM0Go1Rtzd48GCDT+oWFRWFZ5991qCfaQonT57Ec889B39/f8hkMqtPWoyaiEydOhXr1q3Dv/71Lzg5OeHy5cu4fPkyysvLjblZIoul1WoBADb/nYK9peqWLykpMXhM1D6tWbMGEDpsfsEBEDpe+rtNVVWV0T67rKwM9957L5YsWQIfHx+jbcdcGDURWbVqFYqLizF48GB07NhR//jhhx+MuVkii6VS1SYUugptq9arW97JycngMZH1+/PPP3Hs2LF6jy+/+BzPhcgR4inH6BA5/m/VyjuW+fPPPw2y/aioKOzduxdxcXGQyWSQyWS4cOECAODUqVN4+umnoVKp4O3tjUmTJtWrziQmJqJnz55wcHCAh4cHnnjiCZSWluL999/HmjVrsGXLFv1nNtZBdfDgwZg2bRqmTZsGV1dXeHh4YP78+fUudfr7+2PRokWIioqCi4sLXn31VQD/HUczaBAcHBzg6+uL6Ojoer2yrl69ihEjRsDBwQEBAQH47rvvmv15PPTQQ/j000/xwgsvQKFQtOEnalmMevsur1cTtY6Hhwe6BQbhSlYaHEMebfF65dlp6BYY1Oit8URNiXxxPH7es6/ea3IbGb6JdAAATH2oA8ITcvDggw/WW+aJxwdh17/33vX24+LikJWVhR49euDDDz8EAHh5eSE/Px/h4eF49dVXERMTg/Lycrz99tsYN24c/v3vfyM/Px/jx4/HJ598glGjRqGkpAT79u2DEAKzZ8/G6dOncePGDaxevRpA460jgNoK0Msvv4xDhw7hyJEj+Otf/4quXbvqEw4A+PTTT7FgwQLMnz8fAHDixAmo1WosXLgQX3/9Na5du6ZPaOq2GRUVhby8PPz73/+GnZ0doqOjcfXq1bv+mVkTzjVDZEZkMhmmT30DM996C67a6y0asFqtLUR5VhqiY2Igk8lMECVZm8lTXsGBQ+noIKqw4ik7hHrJ4WYvQ4BbbdH8UT9bnJvuiOsVAqeu1WDajirclNlhUtTLBtm+i4sL7OzsoFQq612KWLVqFfr27YuPP/5Y/9o333wDX19fZGVlQavVorq6GqNHj0bXrl0BAD179tQv6+DggMrKyhZd3vD19UVsbCxkMhmCg4Nx4sQJxMbG1ktE/vKXv2D27Nn655MnT8aECRP0Y1sCAwOxfPlyhIeHY9WqVcjNzcWOHTtw8OBBPPLIIwCAr7/+Gvfdd1/bflBWyvpmLyKycJGRkXBUKlGYvBxCV9PkskJXg6LkeCiVSkyePNlEEZK1mTx5MtKPHEVn/+54bftN/OdqjT4JqRPgZoMTV2rw2vab6BIQiPQjR43+O3f06FHs3r0bKpVK/wgJCQEAnD9/Hr1798aQIUPQs2dPjB07Fl999RWuX7/epm3179+/XiI/YMAAZGdno6bmf3+D/fr1uyO+hISEevGp1WrodDrk5OTg9OnTsLW1rbdeSEgIXF1d2xSjtWIiQmRmXF1dkbhhAyovZECzaRGqtQ3fCVOtLYRm0yJUXMhAUmIi/3GjuxIaGorDR47hmVFjELm5Avklunrv55foELWlAiNHj8XhI8cQGhpq9Jh0Oh1GjBiBzMzMeo/s7GwMGjQIcrkcu3btwo4dOxAaGor4+HgEBwcjJyfHKPE4OjreEd9rr71WL7bjx48jOzsb3bp10w9PYKWyabw0Q2SG1Go1tm/bhjFjxyL/iylwCAqDQ+D/5popz05DeVYalEolftq+HREREVKHTFbA0dERg8LDkZj4I9wcak+eJZUCTgoZ3BxksJXLMCg8HEql0uDbtrOzq1d9AIC+ffsiKSkJ/v7+sLVt+HQlk8kwcOBADBw4EO+99x66du2KTZs2YdasWQ1+ZmMOHjx4x/PAwEDI5Y03Fezbty9OnjyJ7t27N/j+fffdh+rqahw5cgQPP/wwAODs2bPsgnwbVkSIzJRarUZebi5iY2LgU30Fmq1LcfXHBdBsXQqf6iuIjYnBxbw8JiFkUEePHkUPbzvU6IApWyrgvKQEL22pgE4A999jh6NHjxplu/7+/jh06BAuXLgAjUYDnU6HqVOnorCwEOPHj8fhw4fx+++/IyUlBS+99BJqampw6NAhfPzxxzhy5Ahyc3OxceNGXLt2TT8Gw9/fH7/99hvOnj0LjUaDmzdvNrr9vLw8zJo1C2fPnsX333+P+Ph4vPnmm03G/Pbbb+PAgQOYOnWqvlKzdetWTJ8+HQAQHByMoUOH4tVXX8WhQ4dw9OhRvPLKK3BwcGjyc6uqqvQVlqqqKvz555/IzMzEuXPnWvlTtRDCjBUXFwsAori4WOpQTE6n04lr166JnJwcce3aNaHT6aQOiSSk0+mERqMROTk5QqPR8PeBGlReXi5OnTolysvL2/wZD/S8XzzmJxeh3nZC6WAvZs6cKZQO9uJ+bzvxqJ9cPNCrhwEj/p+zZ8+K/v37CwcHBwFA5OTkCCGEyMrKEqNGjRKurq7CwcFBhISEiBkzZgidTidOnTol1Gq18PLyEgqFQgQFBYn4+Hj9Z169elU8+eSTQqVSCQBi9+7dDW47PDxcvPHGG+L1118Xzs7Ows3NTcydO7fe31nXrl1FbGzsHesePnxYvw1HR0fRq1cv8dFHH+nfz8/PF8OGDRMKhUL4+fmJtWvXNvpZdXJycgSAOx7h4eGt+ZEaXVO/b605f8uEMN97bFszjbC1KCoqwpo1axC/8nOcz87Sv94tMAjTp76ByMhIjgUgogY1NS17S9d3clKhuroG998XjB8TNyI0NBSnTp3C2OdG4dSZLNjaylFSom3T55urwYMH44EHHrD6DqaG1tTvW2vO37w0Y0aSk5Ph6+eHmW+9hSu2PvAcORf3PL8IniPn4oqtD2a+9RZ8/fyQnJwsdahEZIXKy8vRt1cPvDRlSr0BqXUDWadEReHB3j1RUVEhcaRkTThY1UwkJydj2PDhUPj3QWd19B39IxxDHoWr9joKk5dj2PDh2L5tG9RqtUTREpE1cnNzw4H0Y7CxufM7qqOjI75ZvRo6na7B94naiomIGSgqKsKYsWOh8O8Dz1HzG536Xa5yg+eo+dBsWoQxY8ciLzeXl2mIyKCaSzKsMQlprPU7mYb1/UZZoDVr1qC0rAzu6uhGk5A6Mhs53NTTUVZWJukkVEIIaDQa/Qh3Mx5qREREZoyJiMSEEIhf+TmUQQNb1M4bAGxV7nAICsPyFStNngAUFRUhLi4OgcEh8PLyQkBAALy8vBAYHIK4uDjeH09ERK3CRERiBQUFOJ+dBYegsFat5xAYhvPZWSgsbLjrpjFwMC2RZdDpdM0vRHSXDPVFmGNEJKbV1k7fbmOvatV6dcuXlJTAw8PD4HHd7tbBtJ0ipkMml0PcrICsgz1sHJw5mJbIDNjZ2cHGxgaXLl2Cl5cX7Ozs2F6cjEIIgWvXrkEmk6FDhw539VlMRCSmUtUmFLoKbavWq1veycnJ4DHdrm4wrZ1vT9j59caV9e+guvCi/n1b9y5w6vMUVD2GcDAtkYRsbGwQEBCA/Px8XLp0SepwyMrJZDJ06dKlyTb4LcFERGIeHh7oFhiEK1lpcAx5tMXrlWenoVtgENzd3Y0YXa01a9ZAW1oKWeUZlP/xG5RBYXB97EX9vCdlZ/fj+u5vULTvO3iNfBtu6unI/2IK1q5di+joaKPHR0T/Y2dnBz8/P1RXV7d4nhWitujQocNdJyEAExHJyWQyTJ/6Bma+9RZctddbNGC1WluI8qw0RMfEGL3sKoTA0k8+BYSAvW8PeAxtuMdJjfY6CnYux9WkD3HPc+/pB9NOnz6dpWEiE6srl99tyZzIFDhY1QxERkbCUalEYfJyCF3T32CErgZFyfFQKpWYPHmy0WP7/fffkZ+fD/uAB+E1en6jiZJc5Qav0fPhENAX17YshcK/r8kH0xIRkeVhImIGXF1dkbhhAyovZECzaRGqtQ2fvKu1hdBsWoSKCxlISkw0yfiLul4lnk+92aIeJ+5Dp0NUV6IqPxtA7WBaIiKixvDSjJlQq9XYvm0bxowdi/wvpsAhKAwOgWH6cRjl2Wkoz0qDUqnET9u3m2TqdyEEvl33HZTBYa3qcaIMCkP5uUMATDOYloiILBcTETOiVquRl5uLtWvXYvmKlTi/dan+vW6BQYiOiUFkZCRcXFxMEk9BQQFyfj8Pz5FjW7WeMigMZWf2wf/ebiYZTEtEZA6EECgoKIBWq4VKpYKHhwfHyLUAL82YGVdXV0RHRyP77BloNBrk5ORAo9Eg++wZREdHmywJAe6+x8nkFyfyj5CIrB47Tt8dVkTMlEwmg4eHh0malTXmbnucREZGGjwmIiJzkpycjDFjx6K0rAyOQQPhOXK0/pL6law0zHzrLcxfsACJGzawyWMjmIgYmDWV5tra46Ts7K/o1LkLAgICjBgdEZG0bu043VndcGsDdpxuHi/NGIg1lubqepyUZu1HjfZ6i9ap1haiPPsg3p7zd4tNwIiImlPXcVrh3weeo5pubeA5aj4U/n0wZuxYizwXGBsTEQOw5sng2tLjxNHRND1OiIiksmbNGpSWlcFdHd2i1gZu6ukoKyvTt0Sg/5EJU88j3wo3btyAi4sLiouL4ezsLHU4Dbq1NOfeQGkOAGr+W5qrvJBhkaW5W/fRTT0dtqo774Sp1hbienI8Ki9kmOz2YiIiKQghEBgcgsu2PvB8Zk6L19NsXQqf6ivIPnvG6ivGrTl/MxG5C0VFRfD184POOwSeo+Y3mRULXQ00mxbB5soZi5wMrm5AVllZWZM9TpISE5mEEJFV02g08PLygufIua0aP1d6eh80W5dCo9FIeiOCKbTm/M1LM3ehPZXm6nqcxMbEwKf6CjRbl+Lqjwv0GX5sTAwu5uUxCSEiq3e3rQ3Ycbo+VkTaqD2X5oQQKCwsRElJCZycnODu7m6x+0JE1FqsiDSPFRETKCgowPnsLDgEhbVqPYfAMIufDK6ux4m/v79F355MRNQWda0NKrLSWrVeeXYaugUGseP0bZiItBFLc0RE7VObWxtkpSF62lR+ebsNE5E2utuuo5wMjojIckVGRkLp4ADNjmUtbm2gVLK1QUOYiLQRS3NERO2XTCZDqVaLit+PQbNxIaq1DV9ur9YWQrNpESouZCApMdHi7pg0BbZ4b6O60tzMt96Cq/Z6o131bqUvzcXEsDRHRGShKioq9AnFiy9OxOYtW5D/xZQmWxuwv1LjeNfMXWhtH5GCTYsgs9A+IkREBNTU1MDWtvY7/Msvv4x//vOfKCoqwtq1a7F8xUqcz87SL9stMAjR06YiMjLSpDOnmwM2NDMhdh0lImofhBCwsakd0fDEE09g165dd7zP1ga1mIiYGLuOEhFZPzc3NxQVFSEgIAC///671OGYNSYiEmBpjojIej300EM4cuQIAECn07XbSkdLMRGREEtzRIYnhEBBQQG0Wi1UKhUb6ZFJjRs3Dhs2bABQO0ak7vIMNY6dVSXErqNEhlNUVIS4uDgEBofAy8sLAQEB8PLyQmBwCOLi4lBUVCR1iGTlZs+erU9CqqqqmIQYASsiRGSW6sZelZaVwTFoIOyD/jf2qiIrDaVZ++GoVCJxwwao1WqpwyUrFBsbi1mzZgGo7abt6OgocUSWw2wqIr/88gtGjBiBTp06QSaTYfPmzcbcHBFZibq70XTeIej8egI8npkDx5BH4eD/ABxDHoXHM3PQ+fUE6LxDMGz4cCQnJ0sdMlmZ77//Xp+EXLt2jUmIERk1ESktLUXv3r2xYsUKY26GiKxIUVERxowdC4V/H3iOmt9os0C5yg2eo+ZD4d8HY8aO5WUaMpjU1FRMmDABAJCTkwNPT0+JI7JuRk1EnnrqKSxatAijR4825maIyIqsWbMGpWVlcFdHN9kkEABkNnK4qaejrKwMa9euNVGEZM2OHTuGJ598EgBw/Phx+Pv7SxtQO2BWo24qKytx48aNeg8iaj+EEIhf+TmUQQNbNG0CANiq3OEQFIblK1bCjIe8kQU4f/48HnzwQQDA7t270atXL4kjah/MKhFZvHgxXFxc9A9fX1+pQyIiEyooKMD57Cw4BIW1aj2HwDCcz85CYWHDE48RNefq1avo3r07AODHH3/E4MGDpQ2oHTGrRGTevHkoLi7WP/Ly8qQOiYhMSKvVAgBs7FWtWq9u+ZKSEoPHRNZPq9XC29sbABAfH4+xY8dKHFH7Ylaz7yoUCigUCqnDICKJqFS1CYWuQtuq9eqWd3JyMnhMZN2qqqr0vzfz5s3DtGnTJI6o/TGriggRtW8eHh7oFhiEiqy0Vq1Xnp2GboFBcHe/c9JJosbodDr9l9+JEyfi448/ljii9smoiYhWq0VmZiYyMzMB1N4GlZmZidzcXGNulogslEwmw/Spb6A0az9qtNdbtE61thDlWWmInjaVnYypxYQQkMtr78oaOHAg1q1bJ3FE7ZdRO6vu2bMHjz/++B2vR0ZGIiEhodn12VmVqP0pKiqCr58fdN4h8Bw1v8lbeIWuBgWbFkF25QzycnPh6upqukDJonXu3BmXLl2Cj48P8vPzpQ7H6rTm/G3UMSKDBw/m7XRE1Cqurq5I3LABw4YPh2bTIripp8NWdecll2ptIa4nx6PyQgZ+2r6dSQi12KBBg3Dp0iUA0P+XpGNWg1WJiABArVZj+7ZtGDN2LPK/mAKHoDA4BP5vrpny7DSUZ6VBqVTip+3bERERIXXIZCEiIyOxb98+ALUz6fJynvSYiBCRWVKr1cjLzcXatWuxfMVKnN+6VP9et8AgRMfEIDIyEi4uLhJGSZbk3Xff1Xfgrays5Ey6ZoKz7xKR2RNCoLCwECUlJXBycoK7uzu/yVKrfP7555g6dSqA2nMLb/U2LrMZI0JEZAgymQweHh7w8PCQOhSyQElJSfok5PLly0xCzAzrUkREZLX27t2LMWPGAADOnTun76BK5oOJCBERWaUTJ07o54w5cuQIunXrJm1A1CAmIkREZHX++OMP/ey5KSkp+ll1yfwwESEiIqtSUFAAf39/AMB3332HJ598UtqAqElMRIiIyGqUlZXB09MTAPDZZ59hwoQJEkdEzWEiQkREVuHmzZtwdHQEAMycORNvvfWWxBFRSzARISIii6fT6WBnZwcAeO655xATEyNxRNRSTESIiMii3TqTbp8+fZCYmChxRNQaTESIiMiiBQUFAQCcnZ1x7NgxiaOh1mIiQkREFiEtLQ0DBj6KtLQ0/WtqtRrnzp0DABQVFUkUGd0NJiJERGQR4uNX4GDafqxYsRIA8Ne//hUpKSkAgOrqas4/ZKE41wwREZk9jUaDpKQk2Lp3QWJiIvz8fPHVV18BAMrLy/VjRMjysCJCRERmb82aNagRAveMfhfVOh2WLl0KoPZyjL29vcTR0d1gRYSIiMzKn3/+iStXrtR77fMv/g8OQWHo4OELh8ABKDu7Hzt3/ITz58/rl/H29kbnzp1NHS7dJSYiRERkVsa/OAn79uyu95rMRo57xr8KAHB6cDjKz+7H0KFD6y0z6PG/YO+/fzZZnGQYTESIiMisvDIlCumHDuGmkMH1idfRwcMXNvYqdHD1AQDYd7kfHf/6JXQVWtwsyENR6hfoIBN4OSpS4sipLThGhIiIzMrkyZNx9Eg6uvv7oShlJW5q/tAnIXU6uPrg5rU/UJSyEoEBXXH0SDomT54sUcR0N5iIEBGR2QkNDcXRI+kYM+pZFGyPRbW2sN771dpCFPwUi7GjR+HokXSEhoZKFCndLSYiRERklhwdHREePgiQ2UBurwIA6CrLAAByexVkcjnCwwdBqVRKGSbdJSYiRERktrZt24YOHl0gdDoU/LQMecvGoeCnZRBCB3uvrjh69KjUIdJdkgkhhNRBNObGjRtwcXFBcXExnJ2dpQ6HiIhMTCa3haJTCGSVJYBWg7+9/hpWffF/gNM9EHZKBLp1wInfMqUOk27TmvM3KyJERGSW1qxZA+h0qLx4Ev6eKhw9ko6YmBgcPZKOru4OqLx4CqdPn0RFRYXUodJdYCJCRERmRwiBqKgoQC7Hiy++WG9Aat1A1qioKPTq3YeJiIVjHxEiIjI7n376KQDgaXUEvv322zved3R0xOrVq6HT6WBjw+/UloxjRIiIyKzodDr9JHaVlZWws7OTOCJqLY4RISIiizV16lQAQHR0NJOQdoAVESIiMhtVVVVQKBQAgJqaGl52sVCsiBARkUUaPnw4ACAmJoZJSDvBiggREZmF4uJiuLq6AqgdJyKTyaQNiNqMFREiIrI4ffv2BQBs2LCBSUg7wkSEiIgkd/HiRfz+++8AgDFjxkgcDZkSExEiIpKcr68vAODXX3+VOBIyNSYiREQkqRMnTuj/f+DAgRJGQlJgIkJERJLq1asXAODs2bMSR0JSYCJCRESSSU1NBQCoVCoEBQVJHA1JgYkIERFJ5sknnwQAnDt3TuJISCpMRIiISBJr164FADzwwAPw9vaWOBqSChuaERGRyQkh9J1TtVotHB0dJY6IDMnsGpp9/vnnCAgIgL29PR588EHs27fPFJslIiIztWjRIgDA6NGjmYS0c0ZPRH744QfMmDED7777LjIyMvDYY4/hqaeeQm5urrE3TUREZqimpgbvvfcegNpzBLVvRk9EYmJi8PLLL+OVV17Bfffdh2XLlsHX1xerVq0y9qaJiMgMvfLKKwCAv//977C1tZU4GpKaURORqqoqHD16FBEREfVej4iIQFpamjE3TUREZqiiogIJCQkAgKVLl0obDJkFo6aiGo0GNTU1d4yG9vb2xuXLl+9YvrKyEpWVlfrnN27cMGZ4RERkYmq1GgCwYsUKTmxHAEw0WPX2XzYhRIO/gIsXL4aLi4v+UTf3ABERWb7CwkL88ssvAICpU6dKHA2ZC6MmIp6enpDL5XdUP65evdrgPePz5s1DcXGx/pGXl2fM8IiIyIiEENBoNLhw4QI0Gg169OgBANiyZYvEkZE5MWoiYmdnhwcffBC7du2q9/quXbsQFhZ2x/IKhQLOzs71HkRkWLefHMy4lRBZqKKiIsTFxSEwOAReXl4ICAiAl5cX8i9fAQAMGjRI4gjJnBh9uPKsWbMwadIk9OvXDwMGDMCXX36J3NxcvP7668beNBHdoqioCGvWrEH8ys9xPjtL/3q3wCBMn/oGIiMj4erqKl2AZBWSk5MxZuxYlJaVwTFoIDxHjoaNvQq6Ci3KzvyK8uwD8PXzQ+KGDfrxItS+maSz6ueff45PPvkE+fn56NGjB2JjY1uUEbOzKpFh3H5ysA8K058cKrLSUJq1H45KJU8OdFeSk5MxbPhwKPz7wF0dDbnK7Y5larTXUZi8HJUXMrB92zb+vlmp1py/2eKdyMrx5ECmUFRUBF8/P+i8Q+A5aj5kNvJGlxW6Gmg2LYLNlTPIy81lJc4KmV2LdyK6O20d11FUVIQxY8dC4d8HnqPmN5iEAIBc5QbPUfOh8O+DMWPHoqioyIDRU3uwZs0alJaVwV0d3WQSAgAyGznc1NNRVlamn/iO2i8mIkRmrLFBf4HBIYiLi2s2YeDJgUxBCIH4lZ9DGTSw0WT3drYqdzgEhWH5ipUcMN3O8dIMkZm623EdQggEBofgsq0PPJ+Z0+LtarYuhU/1FWSfPcOGU9QiGo0GXl5e8Bw5F44hj7Z4vdLT+6DZuhQajQYeHh5GjJBMrTXnbzb5JzJDt47r6NzAuA7HkEfh+t9xHcOGD29wXEdBQQHOZ2fBc+ToVm3bITAM57cuRWFhIU8O1CJarRYAYGOvatV6dcuXlJTwd60d46UZIjNjqHEdhjg5ELWESlX7O6Or0LZqvbrlnZycDB4TWQ4mIkRmxlDjOnhyIFPx8PBAt8AgVGS1bjLT8uw0dAsMgru7u5EiI0vARITIjBhy0B9PDmQqMpkM06e+gdKs/ajRXm/ROtXaQpRnpSF62lSORWrnmIgQmZG6cR0OQXdOgdAUh8AwnM/OQmFhof41nhzIlCIjI+GoVKIweTmErqbJZYWuBkXJ8VAqlZg8ebKJIiRzxUSEyIwYelwHTw5kKq6urkjcsAGVFzKg2bQI1drCBper1hZCs2kRKi5kICkxkc3MiHfNEJkTQ4/rqDs5DBs+HJpNi+Cmng5b1Z2XXKq1hbieHI/KCxn4aft2nhyoTdRqNbZv24YxY8ci/4spcAgKg0Pg/247L89OQ3lWGpRKJX7avh0RERFSh0xmgH1EiMxIXe+PK7Y+8DBg74+6niRlZWVNnhySEhN5cqC7VlRUhLVr12L5ipV3TLAYPW0qIiMj4eLiImGEZGyca4bIgsXFxWHmW2+h8+sJLRqwWq0tRP4XUxAbE4Po6OhGl+PJgUxNCIHCwkKUlJTAyckJ7u7uHHvUTjARIbJgrZ08rGDTIshaMXkYTw5EZGyc9I7Ighl70J9MJoOHhwf8/f3h4eHBJISIJMWKCJGZ4rgOIrJUvDRDZCU4roOILBETESIrw3EdRGRJOPsukZWpG9fBGUqJyNpwsCoRERFJhokIERERSYaXZsisCSFQUFAArVYLlUrF202JiKwMKyJkloqKihAXF4fA4BB4eXkhICAAXl5eCAwOQVxcHIqKiqQOkYiIDIB3zZDZqeufUVpWBseggbAP+l//jIqsNJRm7YejUonEDRugVqulDpeIiG7Du2bIYiUnJ2PY8OFQ+PdBZ3X0HXOtOIY8ClftdRQmL8ew4cOxfds2JiNERBaMFREyG62dY0WzaRFsWjHHChERmQbnmiGLtGbNGpSWlcFdHd1kEgIAMhs53NTTUVZWhrVr15ooQiIiMjQmImQWhBCIX/k5lEED77gc0xhblTscgsKwfMVKmHFhj4iImsBEhMxCQUEBzmdnwSEorFXrOQSG4Xx2FgoLG56hloiIzBsTETILWq0WAGBjr2rVenXLl5SUGDwmIiIyPiYiZBZUqtqEQlehbdV6dcs7OTkZPCYiIjI+JiJkFjw8PNAtMAgVWWmtWq88Ow3dAoPg7u5upMiIiMiYmIiQWZDJZJg+9Q2UZu1HjfZ6i9ap1haiPCsN0dOmsu07EZGFYiJCZiMyMhKOSiUKk5dD6GqaXFboalCUHA+lUonJkyebKEIiIjI0JiJkNlxdXZG4YQMqL2RAs2kRqrUN3wlTrS2EZtMiVFzIQFJiIpuZERFZMHZWJbNTN9dMWVkZHILC4BD4v7lmyrPTUJ6VBqVSiaTEREREREgdLhER3aY1528mImSWioqKsHbtWixfsRLns7P0r3cLDEL0tKmIjIyEi4uLhBESEVFjmIiQ1RBCoLCwECUlJXBycoK7uzsHphIRmTnOvktWQyaTwcPDAx4eHlKHQkRERsDBqkRERCQZJiJEREQkGSYiREREJBkmIkRERCQZJiJEREQkGaMmIh999BHCwsKgVCrZ/ZKIiIjuYNREpKqqCmPHjsXf/vY3Y26GiIiILJRR+4h88MEHAICEhARjboaIiIgslFk1NKusrERlZaX++Y0bNySMhoiIiIzNrAarLl68GC4uLvqHr6+v1CERERGREbW6IvL+++/rL7k0Jj09Hf369Wt1MPPmzcOsWbP0z4uLi+Hn58fKCBERkQWpO2+3ZDq7Vici06ZNwwsvvNDkMv7+/q39WACAQqGAQqHQP6/bEVZGiIiILE9JSUmzM6W3OhHx9PSEp6dnm4NqjU6dOiEvLw9OTk5Gm3H1xo0b8PX1RV5entXO8Mt9tA7Wvo/Wvn8A99FaWPs+GmL/hBAoKSlBp06dml3WqINVc3NzUVhYiNzcXNTU1CAzMxMA0L17d6hUqmbXt7GxQZcuXYwZop6zs7NV/kLdivtoHax9H619/wDuo7Ww9n282/1rrhJSx6iJyHvvvYc1a9bon/fp0wcAsHv3bgwePNiYmyYiIiILYNS7ZhISEiCEuOPBJISIiIgAM7t9VwoKhQL/+Mc/6g2StTbcR+tg7fto7fsHcB+thbXvo6n3TyZacm8NERERkRG0+4oIERERSYeJCBEREUmGiQgRERFJhokIERERScaqE5Hq6mrMnz8fAQEBcHBwwL333osPP/wQOp2uyfX27t2LBx98EPb29rj33nvxxRdfmCji1mvLPu7ZswcymeyOx5kzZ0wYeeuUlJRgxowZ6Nq1KxwcHBAWFob09PQm17Gk49ja/TP3Y/jLL79gxIgR6NSpE2QyGTZv3lzvfSEE3n//fXTq1AkODg4YPHgwTp482eznJiUlITQ0FAqFAqGhodi0aZOR9qB5xtjHhISEBo9rRUWFEfekcc3t48aNG6FWq+Hp6QmZTKZvWtkcSzqObdlHczqOTe3fzZs38fbbb6Nnz55wdHREp06dMHnyZFy6dKnZzzXkMbTqRGTp0qX44osvsGLFCpw+fRqffPIJPv30U8THxze6Tk5ODp5++mk89thjyMjIwDvvvIPo6GgkJSWZMPKWa8s+1jl79izy8/P1j8DAQBNE3DavvPIKdu3ahW+//RYnTpxAREQEnnjiCfz5558NLm9px7G1+1fHXI9haWkpevfujRUrVjT4/ieffIKYmBisWLEC6enp8PHxwZNPPomSkpJGP/PAgQN4/vnnMWnSJBw/fhyTJk3CuHHjcOjQIWPtRpOMsY9AbTfLW49pfn4+7O3tjbELzWpuH0tLSzFw4EAsWbKkxZ9pacexLfsImM9xbGr/ysrKcOzYMSxYsADHjh3Dxo0bkZWVhWeeeabJzzT4MRRWbNiwYeKll16q99ro0aPFiy++2Og6c+bMESEhIfVee+2110T//v2NEuPdass+7t69WwAQ169fN3J0hlFWVibkcrnYtm1bvdd79+4t3n333QbXsaTj2Jb9s6RjCEBs2rRJ/1yn0wkfHx+xZMkS/WsVFRXCxcVFfPHFF41+zrhx48TQoUPrvaZWq8ULL7xg8Jhby1D7uHr1auHi4mLESNvu9n28VU5OjgAgMjIymv0cSzqOt2rNPprrcWxq/+ocPnxYABB//PFHo8sY+hhadUXk0Ucfxc8//4ysrCwAwPHjx/Hrr7/i6aefbnSdAwcOICIiot5rarUaR44cwc2bN40ab1u0ZR/r9OnTBx07dsSQIUOwe/duY4faZtXV1aipqbnj24SDgwN+/fXXBtexpOPYlv2rYynH8FY5OTm4fPlyveOjUCgQHh6OtLS0Rtdr7Jg2tY5U2rqPAKDVatG1a1d06dIFw4cPR0ZGhrHDNSlLOo53w1KPY3FxMWQyGVxdXRtdxtDH0KoTkbfffhvjx49HSEgIOnTogD59+mDGjBkYP358o+tcvnwZ3t7e9V7z9vZGdXU1NBqNsUNutbbsY8eOHfHll18iKSkJGzduRHBwMIYMGYJffvnFhJG3nJOTEwYMGICFCxfi0qVLqKmpwbp163Do0CHk5+c3uI4lHce27J+lHcNbXb58GQAaPD517zW2XmvXkUpb9zEkJAQJCQnYunUrvv/+e9jb22PgwIHIzs42arymZEnHsa0s9ThWVFRg7ty5mDBhQpOT3Rn6GBp10jup/fDDD1i3bh3+9a9/4f7770dmZiZmzJiBTp06ITIystH1ZDJZvefiv81nb3/dHLRlH4ODgxEcHKx/PmDAAOTl5eGzzz7DoEGDTBV6q3z77bd46aWX0LlzZ8jlcvTt2xcTJkzAsWPHGl3Hko5ja/fPEo/h7Ro6Ps0dm7asI6XWxtu/f3/0799f/3zgwIHo27cv4uPjsXz5cqPFaWqWdhxbyxKP482bN/HCCy9Ap9Ph888/b3Z5Qx5Dq66I/P3vf8fcuXPxwgsvoGfPnpg0aRJmzpyJxYsXN7qOj4/PHVnd1atXYWtrCw8PD2OH3Gpt2ceG9O/f36yz9W7dumHv3r3QarXIy8vD4cOHcfPmTQQEBDS4vKUdx9buX0PM/RjW8fHxAYAGj8/t37JuX6+160ilrft4OxsbGzz00EMWcVxbypKOo6GY+3G8efMmxo0bh5ycHOzatavJaghg+GNo1YlIWVkZbGzq76JcLm/y1tYBAwZg165d9V5LSUlBv3790KFDB6PEeTfaso8NycjIQMeOHQ0ZmlE4OjqiY8eOuH79OpKTkzFy5MgGl7O041inpfvXEEs5hgEBAfDx8al3fKqqqrB3716EhYU1ul5jx7SpdaTS1n28nRACmZmZFnFcW8qSjqOhmPNxrEtCsrOzkZqa2qIvagY/hm0a4mohIiMjRefOncW2bdtETk6O2Lhxo/D09BRz5szRLzN37lwxadIk/fPff/9dKJVKMXPmTHHq1Cnx9ddfiw4dOojExEQpdqFZbdnH2NhYsWnTJpGVlSX+85//iLlz5woAIikpSYpdaJGdO3eKHTt2iN9//12kpKSI3r17i4cfflhUVVUJISz/OLZ2/8z9GJaUlIiMjAyRkZEhAIiYmBiRkZGhH4m/ZMkS4eLiIjZu3ChOnDghxo8fLzp27Chu3Lih/4xJkyaJuXPn6p/v379fyOVysWTJEnH69GmxZMkSYWtrKw4ePGjy/RPCOPv4/vvvi507d4rz58+LjIwMMWXKFGFraysOHTpk8v0Tovl9LCgoEBkZGWL79u0CgFi/fr3IyMgQ+fn5+s+w9OPYln00p+PY1P7dvHlTPPPMM6JLly4iMzNT5Ofn6x+VlZWN7p+hj6FVJyI3btwQb775pvDz8xP29vbi3nvvFe+++269H3BkZKQIDw+vt96ePXtEnz59hJ2dnfD39xerVq0yceQt15Z9XLp0qejWrZuwt7cXbm5u4tFHHxXbt2+XIPqW++GHH8S9994r7OzshI+Pj5g6daooKirSv2/px7G1+2fux7Du9uLbH5GRkUKI2ttb//GPfwgfHx+hUCjEoEGDxIkTJ+p9Rnh4uH75Ohs2bBDBwcGiQ4cOIiQkRNLEyxj7OGPGDOHn5yfs7OyEl5eXiIiIEGlpaSbcq/qa28fVq1c3+P4//vEP/WdY+nFsyz6a03Fsav/qbklu6LF79279Zxj7GMqE+O8IPiIiIiITs+oxIkRERGTemIgQERGRZJiIEBERkWSYiBAREZFkmIgQERGRZJiIEBERkWSYiBAREZFkmIgQERGRZJiIEBERkWSYiBAREZFkmIgQERGRZJiIEBERkWT+P/b9v01CoqYrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=2) #if this doesn't work comment it out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the number of neighbours from 1 to 3 and 5. Are the predictions the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here (if the above code does not work, there is no need to attempt this section \n",
    "#\n",
    "for i in range(0, 3):\n",
    "    mglearn.plots.plot_knn_classification(n_neighbors=i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 K-Nearest Neighbour Classification with sklearn \n",
    "\n",
    "Now let’s look at how we can apply the k-nearest neighbors algorithm using scikit-learn. The following code loads a dataset of two classes. The data is split into a training and a test set so we can evaluate generalization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.3)\n",
    "print(X.shape,X_train.shape,X_test.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train,marker='+')\n",
    "plt.scatter(X_test[:,0],X_test[:,1],c=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the KNN classifier on the training data and then make predictions on the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(y_test)\n",
    "print(\"Test set predictions: {}\".format(clf.predict(X_test)))\n",
    "print(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For two-dimensional datasets, we can also illustrate the prediction for all possible test points in the xy-plane. We color the plane according to the class that would be assigned to a point in this region. This lets us view the decision boundary, which is the divide between where the algorithm assigns class 0 versus where it assigns class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Set the limit for the X and Y axis based on the data  \n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# Create a mesh \n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "# predict the class at each mesh point \n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)    \n",
    "plt.pcolormesh(xx, yy, Z,shading='auto')\n",
    "# scatter plot of all the data points \n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the prediction for all possible test points for 3 different values of $k$. (Run the code above for different values of $k$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. K-NN Regression\n",
    "There is also a regression variant of the k-nearest neighbors algorithm. Again, let’s start by using the single nearest neighbor, this time using the wave dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase the number of neighbours to 3 and then 9. What do you see? If possible use a 'for' loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-nearest neighbors algorithm for regression is implemented in the `KNeighborsRegressor` class in scikit-learn. It’s used similarly to `KNeighborsClassifier`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "\n",
    "# split the wave dataset into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# instantiate the model and set the number of neighbors to consider to 3\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# fit the model using the training data and training targets\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set predictions:\\n\", reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the model using the score method, which for regressors returns the $R^{2}$ score. The $R^{2}$ score, also known as the coefficient of determination, is a measure of goodness of a prediction for a regression model, and yields a score between 0 and 1. A value of 1 corresponds to a perfect prediction, and a value of 0 corresponds to a constant model that just predicts the mean of the training set responses, y_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set R^2: {:.2f}\".format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our one-dimensional dataset, we can see what the predictions look like for all possible feature values. To do this, we create a test dataset consisting of many points on the line: (ask students to write this) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# create 1,000 data points, evenly spaced between -3 and 3\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # make predictions using 1, 3, or 9 neighbors\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"{} neighbor(s)\\n train score: {:.2f} test score: {:.2f}\".format(\n",
    "            n_neighbors, reg.score(X_train, y_train),\n",
    "            reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Target\")\n",
    "axes[0].legend([\"Model predictions\", \"Training data/target\",\n",
    "                \"Test data/target\"], loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear regression\n",
    "The goal of regression is to find the relationship between the output (Y) and input(s) (X). In linear regression we assume that Y and X are related with the following equation: \n",
    "\\begin{equation}\n",
    "y = mx + b\n",
    "\\end{equation}\n",
    "where m is the scale factor or coefficient, b being the bias coefficient. \n",
    "\n",
    "The goal is to draw the line of best fit between X and Y which estimates the relationship between X and Y by finding these two coeffients. \n",
    "\n",
    "One approach is the ordinary least mean square method where the coefficient are determined by:\n",
    "\\begin{equation}\n",
    "m  = \\frac{\\sum_{i}(x_{i} - \\bar{x_{i}})(y_{i} - \\bar{y_{i}})}{\\sum_{i}(x_{i} - \\bar{x_{i}})^{2}}\n",
    "\\end{equation}\n",
    "\n",
    "and the intercept by\n",
    "\\begin{equation}\n",
    "b = \\bar{y_{i}} - m \\bar{x_{i}}\n",
    "\\end{equation}\n",
    "where $\\bar{x_{i}}$ and $\\bar{y_{i}}$ are the mean of x and y \n",
    "\n",
    "We will first use the functions in scikit-learn.  First, load these packages and a dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folliwing code splits the data into training and testing, fits the training data and display the line of best fit. The input `random_state` controls the shuffling applied to the data before splitting. You can use different numbers for different shuffling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(X_train.shape,y_train.shape, X_test.shape)\n",
    "plt.figure()\n",
    "plt.plot(X_train,y_train,'b.')\n",
    "plt.plot(X_test,y_test,'cd')\n",
    "# y = mx + b \n",
    "yPred = lr.coef_*X_train +lr.intercept_\n",
    "plt.plot(X_train,yPred,'r+' )\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “slope” parameters (w), also called weights or coefficients, are stored in the coef_\n",
    "attribute, while the offset or intercept (b) is stored in the intercept_ attribute. Print these values out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lr.coef_:\", lr.coef_)\n",
    "print(\"lr.intercept_:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s compute the training set and test set performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a K-nearest neighbour regression on the same dataset for comparison.\n",
    "1. Instantiate the model (call KNeighborsRegressor) with n_neighbors=3\n",
    "2. Fit the K-NN model using training data and training targets\n",
    "3. Predict the target (y-values) for X_train and display the results.  \n",
    "4. Compute at the training set and test set performance.\n",
    "5. Display the line of best fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#\n",
    "# Your code goes here \n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Polynomial Regression\n",
    "You can use linear regression with `polynomials` of the original features to appoximate non-linear fucntions. For a given feature `x`, we might want to consider `x**2`,`x**3`,`x**4` and so on. The function `PolynomialFeatures` generates a feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. \n",
    "The following code creates polynomail features from a given feature `x'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a 1D array of numbers\n",
    "X = np.array([1,-2,3,-4])\n",
    "print(X.shape)\n",
    "# reshape the 1D array to a 2D array\n",
    "X = X.reshape(-1,1)\n",
    "print(X.shape)\n",
    "\n",
    "# include polynomials up to x ** 10:\n",
    "# the default \"include_bias=True\" adds a feature that's constantly 1\n",
    "poly = PolynomialFeatures(degree=10, include_bias=False)\n",
    "poly.fit(X)\n",
    "X_poly = poly.transform(X)\n",
    "\n",
    "#print original feature values\n",
    "print('X =\\n', X)\n",
    "#print polynomial features \n",
    "print('X_poly =\\n', X_poly) \n",
    "#get exponent of each feature \n",
    "print(\"Polynomial feature names:\\n{}\".format(poly.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code show how to use polynomial features with a linear regression model (perform polynomial regression). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(size=400)\n",
    "y = np.sin(1.5*X)\n",
    "# Make sure that it X is 2D\n",
    "X_train = X[:, np.newaxis]\n",
    "\n",
    "# create test set \n",
    "X_test = np.random.normal(size=200)\n",
    "y_test = np.sin(1.5*X_test)\n",
    "X_test = X_test[:, np.newaxis]\n",
    "\n",
    "# create a sorted array covering the x axis range \n",
    "x_plot = np.linspace(X.min(), X.max())\n",
    "\n",
    "# create polynomial features with degree 4 \n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit(X_train)\n",
    "X_poly_train = poly.transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "print(X_poly_train.shape, X_train.shape)\n",
    "print(X_poly_test.shape, X_test.shape)\n",
    "\n",
    "reg = LinearRegression().fit(X_poly_train, y)\n",
    "#evaluate on test dat \n",
    "score = reg.score(X_poly_test, y_test)\n",
    "\n",
    "# fit a linear regression and evaluate \n",
    "y_plot = reg.predict( poly.transform(x_plot[:, np.newaxis]))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(x_plot[:, np.newaxis],y_plot,'r')\n",
    "#plt.plot(X_test,reg.predict(X_poly_test),'r')\n",
    "\n",
    "#plt.plot(X_train,reg.predict( poly.transform(X_train)),'r')\n",
    "plt.scatter(X, y, label=\"Samples\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")    \n",
    "#shows the polynomail degree and R2 score (up to 4 decimal places) in the title \n",
    "plt.title(\"Polynomial Degree of 4 \\n R2 = {:.4f}\".format(score))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `pipelines` and `PolynomialFeatures` to approximate a non-linear function. Try implementing a linear regression with polynomial features of degree 1, 3 and 6. \n",
    "1. Create a pipeline glueing together polynomial features and linear regression. \n",
    "2. Fit the pipeline on X_train and evaluate X_test. \n",
    "3. Plot the results. \n",
    "4. Show the polynomail degree and R2 score (up to 4 decimal places) in the title of the plots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Linear regression and KNN on a higher dimensional dataset\n",
    "Let’s see at how LinearRegression performs on a more complex dataset.  Load the California Housing dataset which has 506 samples and 10 derived features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "# take the first 400 instances so that the code runs faster. \n",
    "X = X[:400]\n",
    "y = y[:400]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into testing and training. Fit a linear and KNN regression. How does the test and training set perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the magnitude of the coefficients with a legend  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Ridge regression\n",
    "In ridge regression, the coefficients (m) are chosen not only so that they predict well on the training data, but also to fit an additional constraint to avoid overfitting. We also want the magnitude of coefficients to be as small as possible; in other words, all entries of m should be close to zero. Intuitively, this means each feature should have as little effect on the outcome as possible (which translates to having a small slope), while still predicting well. \n",
    "Fit a Ridge regression on the extended Boston Housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much importance the model places on simplicity versus training set performance can be specified the alpha parameter. \n",
    "The optimum setting of alpha depends on the particular dataset we are using. Increasing alpha forces coefficients to move more toward zero, which decreases training set performance but might help generalization. \n",
    "\n",
    "Compare the performance if you change the value of alpha to 10, 0.1 and 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the magnitude of the coefficients for the ridge regression with different markers, labels the x and y axis as \n",
    "\"Coefficient index\" and \"Coefficient magnitude\" and provides a legend.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "plt.plot(ridge00.coef_, 'x', label=\"Ridge alpha=0.0\")\n",
    "\n",
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-2, 2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Lasso Regression\n",
    "As with ridge regression, using the lasso regression also restricts coefficients to be close to zero. Using the lasso, some coefficients are exactly zero. This means some features are entirely ignored by the model. This can be seen as a form of automatic feature selection. Having some coefficients be exactly zero often makes a model easier to interpret, and can reveal the most important features of your model. The following code fits Lasso regressions on the dataset with different values of alpha (alpha = 1, 0.001, 0.0001). Note that you have to increase the max_iter value (i.e set max_iter=100000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "lasso = Lasso(alpha=10, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))\n",
    "\n",
    "lasso05 = Lasso(alpha=0.5, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"alpha = 0.01: Training set score: {:.2f}\".format(lasso05.score(X_train, y_train)))\n",
    "print(\"alpha = 0.01: Test set score: {:.2f}\".format(lasso05.score(X_test, y_test)))\n",
    "print(\"alpha = 0.01: Number of features used:\", np.sum(lasso05.coef_ != 0))\n",
    "\n",
    "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"alpha = 0.0001: Training set score: {:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
    "print(\"alpha = 0.0001: Test set score: {:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
    "print(\"alpha = 0.0001: Number of features used:\", np.sum(lasso00001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the magnitude of the coefficients for the ridge and lasso regression with different markers. Label the x and y axis as \n",
    "\"Coefficient index\" and \"Coefficient magnitude\". Provide a legend.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Implementing a Simple Linear Regression without scikit-learn libraries  \n",
    "Write code to implement a simple linear regression. First load the \"wave' dataset and split the data into training and testing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Find the mean of X_train and Y_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Calculate the coefficients m and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Plot your predicted solution for linear regression and the actual data points in the same figure. Label your axis as 'X' and 'Y' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code goes here \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Implementing a Gradient Descent for Linear Regression without scikit-learn libraries  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of regression is to find the relationship between the output (y) and input(s) (x). In linear\n",
    "regression we assume that y and x are related with the following equation:\n",
    "\\begin{equation*}\n",
    "y = mx + b \n",
    "\\end{equation*}\n",
    "where m is the scale factor or coefficient, b being the bias coefficient. We can find the values of m and b via gradient descent.  \n",
    "\n",
    "Training a machine learning algorithm is the process of minimizing the cost function. For linear regressions, we use a cost function known as the mean squared error or MSE. \n",
    "The cost function is \n",
    "\\begin{align*}\n",
    "MSE &= \\frac{1}{n}\\sum^{n}_{i=1}(y_{i} - \\hat{y})^{2}  \\\\ \n",
    "& = \\frac{1}{n}\\sum^{n}_{i=1}(y_{i} -(mx_{i} + b))^{2} \n",
    "\\end{align*}\n",
    "\n",
    "The process of finding the optimal values for m and b via gradient descent is to make an initial guess of m and b, \n",
    "iterate multiple times (using a for loop) and at each time, update the values of m and b with the partial derivatives of the cost function. \n",
    "The partial derivatives of m and b are:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial MSE}{\\partial m} &= \\frac{2}{N} \\sum^{N}_{i=1} -x_{i}(y_{i} - (mx_{i} + b)) \\\\\n",
    "\\frac{\\partial MSE}{\\partial b} &= \\frac{2}{N} \\sum^{N}_{i=1} -(y_{i} - (mx_{i} + b)) \n",
    "\\end{align*}\n",
    "\n",
    "These values are calculated each time and added to the current m and b:\n",
    "\\begin{align*}\n",
    "m_{t+1} &= m_{t} - \\lambda \\frac{\\partial MSE}{\\partial m} \\\\ \n",
    "b_{t+1} &= b_{t} - \\lambda \\frac{\\partial MSE}{\\partial b}\n",
    "\\end{align*}\n",
    "Here $\\lambda$ is the learning rate, which determines the speed of convergence. This means how fast gradient descent finds the best parameters. A big $\\lambda$ would mean that the steps we take are too big and that you might miss the lowest point entirely. However, if $\\lambda$ is too small, it will take a long time to fine the optimal parameters.  \n",
    "\n",
    "We will program a gradient descent algorithm to find the optimal m and b for the \"wave\" dataset. The following code loads the wave dataset, splits the dataset into training and testing. \n",
    "We make an initial guess of m_current (m)and b_current (b) and set a learning rate of 0.01. In the `for` loop:\n",
    "1. Compute the cost function or MSE\n",
    "2. Compute the partial derivatives of m and b\n",
    "3. Update the values to the m_current and b_current\n",
    "\n",
    "Try different learning rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "N = float(len(y_train))\n",
    "m_current = 0\n",
    "b_current = 0 \n",
    "learning_rate = 0.05\n",
    "\n",
    "# empty arrays to store the values of cost, m and b\n",
    "cost_append = []\n",
    "m_append = []\n",
    "b_append = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    # predict \n",
    "    y_current = (m_current * X_train) + b_current\n",
    "    \n",
    "    #\n",
    "    # Your code goes here\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
