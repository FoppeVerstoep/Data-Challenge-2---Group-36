{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb2f779-ba44-4874-9799-b4d8bca65a88",
   "metadata": {},
   "source": [
    "## Before running any cells\n",
    "### Download files and setup directory\n",
    "1. In the same directory as this file, make a folder called 'Data'\n",
    "2. Dowload the following files and put them in the 'Data' folder:\n",
    "   - Full burglary data (extract Data.zip in here)\n",
    "   - Code Lookup.csv\n",
    "   - Ethnic Diversity 2021.csv\n",
    "   - Property Prices.csv\n",
    "   - Income Estimates 2020.csv\n",
    "   - LSOA Boundaries 2021.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d4635-7aa2-4cd5-90c8-142d7c8bb64b",
   "metadata": {},
   "source": [
    "### Install necessary packages\n",
    "These 3 cells are originally commented out. Uncomment them by highlighting the lines and pressing ctrl + /\n",
    "\n",
    "If you have run them once on your computer, you shouldn't have to run these lines again. Comment the blocks out again using ctrl + /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bc6eb2-f6ed-41db-81d2-d3481edbab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install osmnx==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f80363d-d77c-42b4-a292-38e6e22e615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ca6ee1-49e2-49b9-b771-911926a23c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install osmnx geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709257fe-be3d-4f3e-825d-18a23e05e946",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e7e4aa-12fb-49d0-858d-1b89922296e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import osmnx.folium as ox_folium\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from collections import deque\n",
    "from shapely.geometry import Point, LineString, MultiPolygon\n",
    "import matplotlib.colors as mcolors\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a771c49-d9a6-44cf-bae9-b85071467744",
   "metadata": {},
   "source": [
    "### Prepare burglary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e140be-6942-4e4d-bf0f-5b43ce769b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of boroughs in London excluding \"City of London\"\n",
    "# LSOA names start with the name of the borough the LSOA is in\n",
    "boroughs = [\"Westminster\", \"Kensington and Chelsea\", \"Hammersmith and Fulham\", \"Wandsworth\", \"Lambeth\", \"Southwark\", \"Tower Hamlets\", \"Hackney\",\n",
    "            \"Islington\", \"Camden\", \"Brent\", \"Ealing\", \"Hounslow\", \"Richmond upon Thames\", \"Kingston upon Thames\", \"Merton\", \"Sutton\", \"Croydon\",\n",
    "            \"Bromley\", \"Lewisham\", \"Greenwich\", \"Bexley\", \"Havering\", \"Barking and Dagenham\", \"Redbridge\", \"Newham\", \"Waltham Forest\", \"Haringey\",\n",
    "            \"Enfield\", \"Barnet\", \"Harrow\", \"Hillingdon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06d7f4b-c6e3-4688-85e1-e12daf893380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with month_year as key\n",
    "# The value will be each corresponding csv file\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Start and end dates\n",
    "start_date = datetime(2021, 1, 1)\n",
    "end_date = datetime(2025, 2, 1)\n",
    "\n",
    "# Dictionary to hold the variables\n",
    "month_vars = {}\n",
    "\n",
    "# Month abbreviation lookup\n",
    "month_abbrs = ['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
    "               'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "# Generate all month keys from start to end\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    key = f\"{month_abbrs[current.month - 1]}_{str(current.year)[-2:]}\"\n",
    "    month_vars[key] = None\n",
    "    # Move to next month\n",
    "    next_month = current.month % 12 + 1\n",
    "    next_year = current.year + (current.month // 12)\n",
    "    current = datetime(next_year, next_month, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b77f7b-eb36-42de-aabd-acf097ed613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the corresponding csv file for every month from start_date to end_date\n",
    "start_year = int(start_date.strftime(\"%y\"))\n",
    "counter = int(start_date.strftime(\"%m\")) - 1\n",
    "for key, value in month_vars.items():\n",
    "    file_name = \"Data/20%02d-%02d/20%02d-%02d-metropolitan-street.csv\" % (start_year + (counter // 12), (counter % 12) + 1, start_year + (counter // 12), (counter % 12) + 1)\n",
    "    month_vars[key] = pd.read_csv(file_name)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f197f962-1d72-44a1-bab7-1904af661776",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in month_vars.items():\n",
    "    month_vars[key].dropna(subset = ['LSOA name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b57e4c8-c6ca-4534-b889-1856e72265d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with names of the months (keys)\n",
    "key_list = [None] * len(month_vars)\n",
    "index = 0\n",
    "for key, value in month_vars.items():\n",
    "    key_list[index] = key\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9121930f-4a3d-4f0a-826c-2fa90e00540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes lots of computation power. Only has to be run once.\n",
    "# For each of the month, only take rows which have LSOA name that starts with one of the boroughs in London\n",
    "# Corresponding to boroughs list\n",
    "b = len(boroughs)\n",
    "months_x_boroughs = len(month_vars) * len(boroughs)\n",
    "df_list = [None] * months_x_boroughs\n",
    "for borough in range(months_x_boroughs):\n",
    "    df_list[borough] = month_vars[key_list[borough // b]][month_vars[key_list[borough // b]]['LSOA name'].str.startswith(boroughs[borough % b])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01badab5-1961-4478-86be-53aa443e53fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every borough had at least one crime in every month from January 2021 to February 2025\n"
     ]
    }
   ],
   "source": [
    "# Find boroughs without any crime in a given month\n",
    "# Take them out of df_list if there wasn't any crime\n",
    "no_crime = []\n",
    "for borough in range(months_x_boroughs):\n",
    "    if df_list[borough].empty:\n",
    "        no_crime.append(borough)\n",
    "if len(no_crime) == 0:\n",
    "    sentence = 'Every borough had at least one crime in every month from %s %s to %s %s' % (start_date.strftime(\"%B\"), start_date.strftime(\"%Y\"), end_date.strftime(\"%B\"), end_date.strftime(\"%Y\"))\n",
    "    print(sentence)\n",
    "else:\n",
    "    for i in range(len(no_crime)):\n",
    "        del df_list[no_crime[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dade0dad-911a-4c19-82f0-2f716f361557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes in df_list into one dataframe\n",
    "merged_df = pd.concat(df_list, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73021088-0c35-48f7-8395-c0172a5e5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "burg_df = merged_df[merged_df['Crime type'] == 'Burglary'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fde836-124a-4582-ae54-595800a2fd81",
   "metadata": {},
   "source": [
    "### Prepare code lookup dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad423907-7ad4-4ebb-829a-84db990a015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV containing LSOA and MSOA codes\n",
    "codes_df = pd.read_csv('Data/Code Lookup.csv', encoding=\"latin1\", low_memory=False)\n",
    "codes_df.rename(columns = {'lsoa21cd': 'LSOA code'}, inplace = True)\n",
    "codes_df.rename(columns = {'msoa21cd': 'MSOA code'}, inplace = True)\n",
    "codes_df.rename(columns = {'msoa21nm': 'MSOA name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fdbb841-b31d-4eae-979b-b8fac5b74afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows within the 32 districts of Greater London (not City of London)\n",
    "districts_df = codes_df[codes_df['ladnm'].isin(boroughs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709c9f33-1e58-46ce-9ca5-152a7d7bfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "msoa_lsoa = districts_df[['LSOA code', 'MSOA code', 'MSOA name']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d360a930-e219-42b6-ae2f-4a2b494cd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msoa_to_lsoa = msoa_lsoa.drop_duplicates(subset = ['LSOA code'], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8914a3e9-6ffd-4936-931e-211444801491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds MSOA code column to burg_df\n",
    "burglar_df = pd.merge(\n",
    "    burg_df,\n",
    "    msoa_to_lsoa,\n",
    "    on = 'LSOA code',\n",
    "    how = 'left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31a964-9486-4428-9670-4734034807bb",
   "metadata": {},
   "source": [
    "#### burglar_df\n",
    "Main dataframe for burglary counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10841525-5d7e-4ea4-8ca5-55889d0fbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds Coordinate column to burglar_df\n",
    "burglar_df['Coordinate'] = list(zip(burglar_df['Longitude'], burglar_df['Latitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e10b1b60-96d8-4015-8662-2b4ae33857e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>Crime type</th>\n",
       "      <th>Last outcome category</th>\n",
       "      <th>Context</th>\n",
       "      <th>MSOA code</th>\n",
       "      <th>MSOA name</th>\n",
       "      <th>Coordinate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75984</th>\n",
       "      <td>ea8188dcb4ee8a2363b900937c460a832fb9eab47c16c8...</td>\n",
       "      <td>2022-06</td>\n",
       "      <td>Metropolitan Police Service</td>\n",
       "      <td>Metropolitan Police Service</td>\n",
       "      <td>-0.150729</td>\n",
       "      <td>51.360833</td>\n",
       "      <td>On or near Railway Approach</td>\n",
       "      <td>E01004170</td>\n",
       "      <td>Sutton 017B</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E02000856</td>\n",
       "      <td>Sutton 017</td>\n",
       "      <td>(-0.150729, 51.360833)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Crime ID    Month  \\\n",
       "75984  ea8188dcb4ee8a2363b900937c460a832fb9eab47c16c8...  2022-06   \n",
       "\n",
       "                       Reported by                 Falls within  Longitude  \\\n",
       "75984  Metropolitan Police Service  Metropolitan Police Service  -0.150729   \n",
       "\n",
       "        Latitude                     Location  LSOA code    LSOA name  \\\n",
       "75984  51.360833  On or near Railway Approach  E01004170  Sutton 017B   \n",
       "\n",
       "      Crime type      Last outcome category  Context  MSOA code   MSOA name  \\\n",
       "75984   Burglary  Status update unavailable      NaN  E02000856  Sutton 017   \n",
       "\n",
       "                   Coordinate  \n",
       "75984  (-0.150729, 51.360833)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burglar_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dff137-c9a0-4171-b1c9-40c089e711b4",
   "metadata": {},
   "source": [
    "### Load Geographical Data\n",
    "Use geopandas (gpd) to read geojson file of geographical data per LSOA\n",
    "\n",
    "*After running this once, lsoas.gpkg will be a file in this directory. Comment out cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578a6bdc-a424-40d3-ada0-d14bde2d8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the huge GeoJSON once (may take a while)\n",
    "# lsoa_gdf = gpd.read_file(\"Data/LSOA Boundaries 2021.geojson\")\n",
    "\n",
    "# # Save it as a much faster binary format\n",
    "# lsoa_gdf.to_file(\"lsoas.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "104e1e34-d531-4e2a-ab79-18a5bd918af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_gdf = gpd.read_file(\"lsoas.gpkg\")\n",
    "lsoa_gdf.rename(columns = {'LSOA21CD': 'LSOA code'}, inplace = True)\n",
    "lsoa_gdf.rename(columns = {'LSOA21NM': 'LSOA name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee7dfc2f-b982-45b6-a3f9-689164b3b025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>LSOA21NMW</th>\n",
       "      <th>BNG_E</th>\n",
       "      <th>BNG_N</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>GlobalID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>E01012431</td>\n",
       "      <td>Halton 012F</td>\n",
       "      <td></td>\n",
       "      <td>351412</td>\n",
       "      <td>382634</td>\n",
       "      <td>53.33838</td>\n",
       "      <td>-2.73117</td>\n",
       "      <td>783466.300911</td>\n",
       "      <td>8043.406248</td>\n",
       "      <td>76e860b4-d325-433b-98f8-b31d8aa2c9c2</td>\n",
       "      <td>MULTIPOLYGON (((-2.72285 53.34449, -2.72246 53...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LSOA code    LSOA name LSOA21NMW   BNG_E   BNG_N       LAT     LONG  \\\n",
       "11798  E01012431  Halton 012F            351412  382634  53.33838 -2.73117   \n",
       "\n",
       "         Shape__Area  Shape__Length                              GlobalID  \\\n",
       "11798  783466.300911    8043.406248  76e860b4-d325-433b-98f8-b31d8aa2c9c2   \n",
       "\n",
       "                                                geometry  \n",
       "11798  MULTIPOLYGON (((-2.72285 53.34449, -2.72246 53...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoa_gdf.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91252042-0942-4a5c-a6d7-4653ece6c8fa",
   "metadata": {},
   "source": [
    "### Create GeoDataFrame per MSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57599538-0015-4605-9121-c01d96ace574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all unique LSOAs\n",
    "msoa_list = msoa_to_lsoa['MSOA code'].unique().tolist()\n",
    "\n",
    "# Gather all LSOAs per MSOA\n",
    "lsoa_per_msoa = [None] * len(msoa_list)\n",
    "for i in range(len(msoa_list)):\n",
    "    lsoa_per_msoa[i] = msoa_to_lsoa[msoa_to_lsoa[\"MSOA code\"] == msoa_list[i]][\"LSOA code\"].unique()\n",
    "\n",
    "# Make list of LSOAs for every MSOA in the same order as msoa_list\n",
    "msoa_gdf = [None] * len(msoa_list)\n",
    "for i in range(len(msoa_gdf)):\n",
    "    msoa_gdf[i] = lsoa_gdf[lsoa_gdf[\"LSOA code\"].isin(lsoa_per_msoa[i])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35695e8-81cc-4ced-acf7-ec3efe6e69d9",
   "metadata": {},
   "source": [
    "## Route Making Algorithms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d910308-ccc7-4a80-81cb-4f7a51ca2f77",
   "metadata": {},
   "source": [
    "find_max_weight_routes() description:\n",
    "Tries all combinations of edges and routes to find the combination of at most k routes with the maximum weight.\n",
    "This algorithm is very computationally expensive and might not terminate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e37fddb-2230-4320-aa14-4ec6cba0eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_weight_routes(G, edges, nodes, k=5, m=1000, M=5000, max_iterations=1000):\n",
    "    # Create working graph (same as before)\n",
    "    working_G = nx.DiGraph()\n",
    "    for (u, v, key), row in edges.iterrows():\n",
    "        length = row.get('length', 0)\n",
    "        weight = row.get('weight', length)\n",
    "        working_G.add_edge(u, v, length=length, weight=weight, key=key)\n",
    "        working_G.add_edge(v, u, length=length, weight=weight, key=key)\n",
    "    \n",
    "    routes_with_weights = []\n",
    "    used_start_edges = set()\n",
    "    \n",
    "    # Get all edges sorted by weight (descending)\n",
    "    all_edges = sorted(\n",
    "        [(u, v) for u, v in working_G.edges()],\n",
    "        key=lambda e: -working_G.edges[e]['weight']\n",
    "    )\n",
    "    \n",
    "    for start_edge in all_edges:\n",
    "        if len(routes_with_weights) >= k:\n",
    "            break\n",
    "            \n",
    "        if start_edge in used_start_edges:\n",
    "            continue\n",
    "            \n",
    "        start_node, next_node = start_edge\n",
    "        best_route, best_weight = None, 0\n",
    "        stack = deque([(\n",
    "            next_node, \n",
    "            [start_node, next_node], \n",
    "            working_G.edges[start_edge]['length'],\n",
    "            working_G.edges[start_edge]['weight'],\n",
    "            {start_edge}\n",
    "        )])\n",
    "        \n",
    "        while stack:\n",
    "            node, route, length, weight, visited = stack.pop()\n",
    "            \n",
    "            # Check cycle completion\n",
    "            if working_G.has_edge(node, start_node):\n",
    "                return_edge = (node, start_node)\n",
    "                if return_edge not in visited:\n",
    "                    total_length = length + working_G.edges[return_edge]['length']\n",
    "                    total_weight = weight + working_G.edges[return_edge]['weight']\n",
    "                    \n",
    "                    if m <= total_length <= M and total_weight > best_weight:\n",
    "                        best_route = route + [start_node]\n",
    "                        best_weight = total_weight\n",
    "                        continue  # Keep looking for heavier cycles\n",
    "            \n",
    "            # Explore neighbors sorted by weight (descending)\n",
    "            for neighbor in sorted(\n",
    "                working_G.neighbors(node),\n",
    "                key=lambda n: -working_G.edges[node, n]['weight']\n",
    "            ):\n",
    "                edge = (node, neighbor)\n",
    "                if edge not in visited:\n",
    "                    edge_data = working_G.edges[edge]\n",
    "                    new_length = length + edge_data['length']\n",
    "                    new_weight = weight + edge_data['weight']\n",
    "                    \n",
    "                    if new_length <= M:\n",
    "                        new_visited = visited.copy()\n",
    "                        new_visited.add(edge)\n",
    "                        stack.append((neighbor, route + [neighbor], new_length, new_weight, new_visited))\n",
    "        \n",
    "        if best_route:\n",
    "            # Check for duplicates\n",
    "            if not any(r == best_route for r, _ in routes_with_weights):\n",
    "                routes_with_weights.append((best_route, best_weight))\n",
    "                used_start_edges.add(start_edge)\n",
    "    \n",
    "    return sorted(routes_with_weights, key=lambda x: -x[1]), working_G"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5480768b-8aaa-4c08-8df3-0f5266523752",
   "metadata": {},
   "source": [
    "find_max_weight_routes_fast() changes:\n",
    "- Keeps track of all_used_edges in both directions\n",
    "    - When route is accepted\n",
    "- Has max_overlap parameter that determines how many edges two distinct routes can have in common (u, v) and (v, u) both count\n",
    "- Use highest weighted unused edge as start edge\n",
    "- Algorithm will try next highest weight edge if previous route was rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec5023db-dfdb-4a6e-ab31-0e986f1f992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_weight_routes_fast(G, edges, nodes, k=5, m=1000, M=5000, max_iterations=100, beam_width=3, neighbor_sample=5, max_overlap=5):\n",
    "    # Create working graph\n",
    "    working_G = nx.DiGraph()\n",
    "    for (u, v, key), row in edges.iterrows():\n",
    "        length = row.get('length', 0)\n",
    "        weight = row.get('weight', length)\n",
    "        working_G.add_edge(u, v, length=length, weight=weight, key=key)\n",
    "        working_G.add_edge(v, u, length=length, weight=weight, key=key)\n",
    "    \n",
    "    routes_with_weights = []\n",
    "    used_start_edges = set()\n",
    "    all_used_edges = []  # List of sets containing used edges for each route\n",
    "    \n",
    "    # Pre-sort all edges by weight\n",
    "    all_edges = sorted(\n",
    "        [(u, v) for u, v in working_G.edges()],\n",
    "        key=lambda e: -working_G.edges[e]['weight']\n",
    "    )\n",
    "    \n",
    "    for start_edge in all_edges:\n",
    "        if len(routes_with_weights) >= k:\n",
    "            break\n",
    "        if start_edge in used_start_edges:\n",
    "            continue\n",
    "            \n",
    "        start_node, next_node = start_edge\n",
    "        best_route, best_weight = None, 0\n",
    "        initial_state = (\n",
    "            next_node,\n",
    "            [start_node, next_node],\n",
    "            working_G.edges[start_edge]['length'],\n",
    "            working_G.edges[start_edge]['weight'],\n",
    "            {start_edge, (next_node, start_node)}  # Track both directions\n",
    "        )\n",
    "        beam = [initial_state]\n",
    "        \n",
    "        while beam and len(routes_with_weights) < k:\n",
    "            new_beam = []\n",
    "            \n",
    "            for state in beam:\n",
    "                node, route, length, weight, visited = state\n",
    "                \n",
    "                # Check cycle completion\n",
    "                if working_G.has_edge(node, start_node):\n",
    "                    return_edge = (node, start_node)\n",
    "                    if return_edge not in visited:\n",
    "                        total_length = length + working_G.edges[return_edge]['length']\n",
    "                        total_weight = weight + working_G.edges[return_edge]['weight']\n",
    "                        \n",
    "                        if m <= total_length <= M and total_weight > best_weight:\n",
    "                            candidate_route = route + [start_node]\n",
    "                            candidate_edges = visited.union({return_edge, (start_node, node)})\n",
    "                            \n",
    "                            # Check overlap with existing routes\n",
    "                            valid = True\n",
    "                            for used_edges in all_used_edges:\n",
    "                                overlap = len(candidate_edges.intersection(used_edges))\n",
    "                                if overlap > max_overlap:\n",
    "                                    valid = False\n",
    "                                    break\n",
    "                            \n",
    "                            if valid:\n",
    "                                best_route = candidate_route\n",
    "                                best_weight = total_weight\n",
    "                                best_edges = candidate_edges\n",
    "                \n",
    "                # Skip if no hope of reaching min length\n",
    "                min_possible_length = length + nx.shortest_path_length(working_G, node, start_node, weight='length')\n",
    "                if min_possible_length > M:\n",
    "                    continue\n",
    "                \n",
    "                # Get top-k heaviest neighbors\n",
    "                neighbors = sorted(\n",
    "                    working_G.neighbors(node),\n",
    "                    key=lambda n: -working_G.edges[node, n]['weight']\n",
    "                )[:neighbor_sample]\n",
    "                \n",
    "                for neighbor in neighbors:\n",
    "                    edge = (node, neighbor)\n",
    "                    reverse_edge = (neighbor, node)\n",
    "                    if edge not in visited and reverse_edge not in visited:\n",
    "                        edge_data = working_G.edges[edge]\n",
    "                        new_length = length + edge_data['length']\n",
    "                        new_weight = weight + edge_data['weight']\n",
    "                        \n",
    "                        if new_length <= M:\n",
    "                            new_visited = visited.copy()\n",
    "                            new_visited.add(edge)\n",
    "                            new_visited.add(reverse_edge)\n",
    "                            new_state = (neighbor, route + [neighbor], new_length, new_weight, new_visited)\n",
    "                            new_beam.append(new_state)\n",
    "            \n",
    "            # Keep only top beam_width states by weight\n",
    "            beam = sorted(new_beam, key=lambda x: -x[3])[:beam_width]\n",
    "        \n",
    "        if best_route:\n",
    "            routes_with_weights.append((best_route, best_weight))\n",
    "            all_used_edges.append(best_edges)\n",
    "            used_start_edges.add(start_edge)\n",
    "            # Also add reverse direction to prevent starting from it\n",
    "            used_start_edges.add((start_edge[1], start_edge[0]))\n",
    "    \n",
    "    return sorted(routes_with_weights, key=lambda x: -x[1]), working_G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b4335-9a66-4cab-bb27-4858a3468ea3",
   "metadata": {},
   "source": [
    "### Find k closest streets to a coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1067c5a-5d53-40b9-a362-ef55908171c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_closest_streets(G, coord, k=5):\n",
    "    \"\"\"\n",
    "    Get the k closest street segments to a given (lon, lat) coordinate.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: street network graph (from osmnx)\n",
    "    - coord: tuple of (longitude, latitude)\n",
    "    - k: number of closest street segments to return\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame with k closest edges and distances in meters\n",
    "    \"\"\"\n",
    "    # Convert graph edges to GeoDataFrame\n",
    "    edges = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
    "\n",
    "    # Create Point from (lon, lat)\n",
    "    point = Point(coord)\n",
    "\n",
    "    # Ensure CRS is projected in meters for distance calculation\n",
    "    if edges.crs.is_geographic:\n",
    "        edges = edges.to_crs(epsg=3857)\n",
    "        point_proj = gpd.GeoSeries([point], crs=\"EPSG:4326\").to_crs(epsg=3857).iloc[0]\n",
    "    else:\n",
    "        point_proj = point\n",
    "\n",
    "    # Compute distance from point to each street (edge)\n",
    "    edges[\"distance\"] = edges.geometry.distance(point_proj)\n",
    "\n",
    "    # Get k closest\n",
    "    closest_edges = edges.nsmallest(k, \"distance\")\n",
    "\n",
    "    return closest_edges[[\"osmid\", \"geometry\", \"distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bff20800-393c-4029-92f9-bcdb0966b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle osmid being a list\n",
    "def explode_osmid(df):\n",
    "    # Turn rows with list osmids into multiple rows (one per osmid)\n",
    "    return df.explode(\"osmid\") if df[\"osmid\"].apply(lambda x: isinstance(x, list)).any() else df\n",
    "\n",
    "def top_close_streets_gdf(G, coordinate, distance=500, k=1000):   \n",
    "    # Use large k to ensure finding unique streets\n",
    "    EDGES = get_k_closest_streets(G, coordinate, k)\n",
    "    EDGES = explode_osmid(EDGES)\n",
    "    \n",
    "    # Drop duplicates by osmid, keeping the one with the shortest distance\n",
    "    unique_osmid = EDGES.sort_values(\"distance\").drop_duplicates(\"osmid\", keep=\"first\")\n",
    "    unique_streets = unique_osmid.sort_values(\"distance\").drop_duplicates(\"distance\", keep = \"first\")\n",
    "    \n",
    "    # Take top-k unique streets (if k large enough, all streets within distance meters of coordinate)\n",
    "    top_k_streets = unique_streets[unique_streets['distance'] < distance]\n",
    "    return top_k_streets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a015f5-daba-4744-a28a-00ab174702e2",
   "metadata": {},
   "source": [
    "### Show coordinate and closest streets on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6571b19-1bbe-44a2-997d-0ef28ce0f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_streets_and_point(coord, street_gdf):\n",
    "    \"\"\"\n",
    "    Visualize a point and its closest street segments using Folium.\n",
    "\n",
    "    Parameters:\n",
    "    - coord: tuple (lon, lat)\n",
    "    - street_gdf: GeoDataFrame with 'geometry' column in lat/lon (EPSG:4326)\n",
    "    \"\"\"\n",
    "    # Make sure the GeoDataFrame is in lat/lon\n",
    "    if street_gdf.crs != \"EPSG:4326\":\n",
    "        street_gdf = street_gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # Initialize folium map centered at the coordinate\n",
    "    m = folium.Map(location=(coord[1], coord[0]), zoom_start=16)\n",
    "\n",
    "    # Add the point marker\n",
    "    folium.Marker(\n",
    "        location=(coord[1], coord[0]),\n",
    "        popup=\"Query Point\",\n",
    "        icon=folium.Icon(color='red')\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add each street as a polyline\n",
    "    for _, row in street_gdf.iterrows():\n",
    "        coords = [(lat, lon) for lon, lat in row.geometry.coords]\n",
    "        folium.PolyLine(\n",
    "            locations=coords,\n",
    "            tooltip=f\"osmid: {row.osmid}\",\n",
    "            color=\"blue\",\n",
    "            weight=5,\n",
    "            opacity=0.7\n",
    "        ).add_to(m)\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c662fc-5ef4-4a49-a17e-8889b4ab52f7",
   "metadata": {},
   "source": [
    "### Burglary Count per Unique Coordinate\n",
    "At an MSOA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ef81564-d74d-4696-b307-b3fb3743bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drops all the rows that do not have a MSOA name (Discuss with the group)\n",
    "burglar_df = burglar_df.dropna(subset=['MSOA name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79b70b18-4a47-4d75-b4e5-43962c4bf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_per_msoa(msoa_input):\n",
    "    # Filter and clean\n",
    "    filtered_df = burglar_df[\n",
    "        (burglar_df[\"MSOA name\"] == msoa_input) &\n",
    "        (burglar_df[\"Coordinate\"].notna()) &                      \n",
    "        (burglar_df[\"Coordinate\"] != \"\") &           \n",
    "        (burglar_df[\"Coordinate\"].str.lower() != \"no coordinate\") \n",
    "    ]\n",
    "\n",
    "    # Count crimes by MSOA and Location\n",
    "    location_counts = (\n",
    "        filtered_df.groupby([\"MSOA code\", \"Coordinate\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"Crime Count\")\n",
    "        .sort_values(by=[\"MSOA code\", \"Crime Count\"], ascending=[True, False])\n",
    "    )\n",
    "\n",
    "    coord_count = {}\n",
    "\n",
    "    for index, row in location_counts.iterrows():\n",
    "        coord = row[\"Coordinate\"]\n",
    "        count = row[\"Crime Count\"]\n",
    "        coord_count[coord] = count\n",
    "\n",
    "    return coord_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4df1e-d86c-4662-ad46-af4b78be0afe",
   "metadata": {},
   "source": [
    "### Add weights to an MSOA's street network\n",
    "For each coordinate:  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Find all streets within a given distance  \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;For each close street:  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Add coord_count[coordinate] * (1 - (current_distance / 400)) to its current weight  \n",
    "\n",
    "coord_count[coordinate] is the burglary count for that unique coordinate  \n",
    "current_distance is the distance of the edge to the unique coordinate  \n",
    "\n",
    "***ignore the PerformanceWarnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1e775aa-b344-4622-9b77-a401affac527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the LSOA code column in codes_df matches the casing of lsoa_gdf\n",
    "codes_df['LSOA code'] = codes_df['LSOA code'].str.upper()\n",
    "\n",
    "# Merge MSOA names into the LSOA geometries\n",
    "merged = lsoa_gdf.merge(\n",
    "    codes_df[['LSOA code', 'MSOA name']],\n",
    "    left_on='LSOA code',\n",
    "    right_on='LSOA code'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8caae010-f350-438d-abad-fd967678e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets all edges from a MSOA and assigns them weights\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def edges_weights_msoa(msoa_input):\n",
    "    \n",
    "    ### Creating the MSOA street graph\n",
    "\n",
    "    # Filter by the MSOA name input\n",
    "    subset = merged[merged['MSOA name'] == msoa_input]\n",
    "\n",
    "    if subset.empty:\n",
    "        raise ValueError(f\"No LSOAs found for MSOA '{msoa_input}'\")\n",
    "\n",
    "    # Combine all LSOA geometries into one polygon\n",
    "    combined_polygon = subset.unary_union\n",
    "\n",
    "    # Simplify the geometry\n",
    "    simplified_polygon = combined_polygon.simplify(0.001)\n",
    "\n",
    "    # Step 2: Get the street network within that area\n",
    "    G = ox.graph_from_polygon(simplified_polygon, network_type=\"drive\")\n",
    "\n",
    "    # Step 3: Convert graph to a folium map\n",
    "    folium_map = ox.folium.plot_graph_folium(G, tiles=\"cartodbpositron\")\n",
    "\n",
    "\n",
    "    # Optional: add LSOA boundary overlay\n",
    "    folium.GeoJson(\n",
    "        subset,\n",
    "        name=f\"msoa_input\" + \"LSOAs\",\n",
    "        style_function=lambda x: {\n",
    "            \"fillColor\": \"none\",\n",
    "            \"color\": \"blue\",\n",
    "            \"weight\": 2,\n",
    "        },\n",
    "    ).add_to(folium_map)\n",
    "\n",
    "    \n",
    "    ### Assigning the weights\n",
    "\n",
    "    G_cop = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
    "    G_copy = explode_osmid(G_cop)\n",
    "    G_copy['weight'] = 0\n",
    "\n",
    "    # Gets the nodes and esges from the MSOA graph\n",
    "    nodes, edges = ox.graph_to_gdfs(G, nodes=True, edges=True)\n",
    "\n",
    "    # Reset the index so 'osmid' becomes a column\n",
    "    edges = edges.reset_index()\n",
    "\n",
    "    coord_count = coords_per_msoa(msoa_input)\n",
    "\n",
    "    for coord in coord_count:\n",
    "        close_streets = top_close_streets_gdf(G, coord, distance=500, k=1000)\n",
    "\n",
    "        # Order of close_distances and close_streets is the same\n",
    "        for index, street in close_streets.iterrows():\n",
    "            current_streets = G_copy.loc[G_copy['osmid'] == street[0]].copy()\n",
    "            for idx, edge in current_streets.iterrows():\n",
    "                current_weight = edge['weight']\n",
    "                current_distance = street['distance']\n",
    "                G_copy.loc[idx, 'weight'] =  current_weight + (coord_count[coord] * (1 - (current_distance/500)))\n",
    "\n",
    "    # Confirm we now have u, v, key\n",
    "    required_columns = ['u', 'v', 'key']\n",
    "    if all(col in edges.columns for col in required_columns):\n",
    "        edges = edges.set_index(required_columns)\n",
    "    else:\n",
    "        raise ValueError(f\"Missing one of the required columns: {required_columns}\")\n",
    "    \n",
    "    if not G_copy.index.names == ['u', 'v', 'key']:\n",
    "        G_copy = G_copy.set_index(['u', 'v', 'key'])\n",
    "\n",
    "    # Get all unique node IDs from edges\n",
    "    u_nodes = G_copy.index.get_level_values('u')\n",
    "    v_nodes = G_copy.index.get_level_values('v')\n",
    "    node_ids = set(u_nodes).union(set(v_nodes))\n",
    "\n",
    "    # Extract node coordinates from the edge geometries (endpoints)\n",
    "    coords = {}\n",
    "    for _, row in G_copy.iterrows():\n",
    "        line = row['geometry']\n",
    "        coords[row.name[0]] = line.coords[0]  # u node\n",
    "        coords[row.name[1]] = line.coords[-1]  # v node\n",
    "\n",
    "    # Create node GeoDataFrame\n",
    "    nodes_data = {\n",
    "        'x': [coords[n][0] for n in coords],\n",
    "        'y': [coords[n][1] for n in coords],\n",
    "        'geometry': [Point(coords[n]) for n in coords],\n",
    "    }\n",
    "    nodes_gdf = gpd.GeoDataFrame(nodes_data, index=list(coords.keys()), crs=G_copy.crs)\n",
    "\n",
    "    # Rebuild the graph now that 'hot' is assigned\n",
    "    G_final = ox.utils_graph.graph_from_gdfs(nodes_gdf, G_copy)\n",
    "\n",
    "    # Get nodes and edges from the rebuilt graph\n",
    "    nodes_final, edges_final = ox.graph_to_gdfs(G_final)\n",
    "\n",
    "    return G_final, nodes_final, edges_final, subset, simplified_polygon   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a139d6-3b11-4643-9fa7-7a55376e9955",
   "metadata": {},
   "source": [
    "### Visualize Graph with Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37b2adc4-2b32-4191-ade8-953a55ddd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def routes_visualize(msoa_input, k=5, m=1000, M=5000, max_iterations=100, beam_width=3, neighbor_sample=5, max_overlap=5):\n",
    "    # Get graph & data\n",
    "    G_final, nodes_final, edges_final, subset, simplified_polygon = edges_weights_msoa(msoa_input)\n",
    "\n",
    "    # Find routes using correct variables and passed parameters\n",
    "    routes, working_G = find_max_weight_routes_fast(\n",
    "        G_final, edges_final, nodes_final,\n",
    "        k=k,\n",
    "        m=m,\n",
    "        M=M,\n",
    "        max_iterations=max_iterations,\n",
    "        beam_width=beam_width,\n",
    "        neighbor_sample=neighbor_sample,\n",
    "        max_overlap=max_overlap\n",
    "    )\n",
    "    \n",
    "    # Base map\n",
    "    map_final = ox.folium.plot_graph_folium(G_final, tiles=\"cartodbpositron\")\n",
    "\n",
    "    # Step 4: Add LSOA boundary overlay\n",
    "    folium.GeoJson(\n",
    "        subset,\n",
    "        name=f\"{msoa_input} LSOAs\",\n",
    "        style_function=lambda x: {\n",
    "            \"fillColor\": \"none\",\n",
    "            \"color\": \"blue\",\n",
    "            \"weight\": 2,\n",
    "        },\n",
    "    ).add_to(map_final)\n",
    "\n",
    "    # Draw each route as red lines\n",
    "    for i, (route, _) in enumerate(routes, start=1):\n",
    "        route_geoms = []\n",
    "        for u, v in zip(route[:-1], route[1:]):\n",
    "            if G_final.has_edge(u, v, 0):\n",
    "                data = G_final.edges[u, v, 0]\n",
    "            elif G_final.has_edge(v, u, 0):\n",
    "                data = G_final.edges[v, u, 0]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if 'geometry' in data:\n",
    "                route_geoms.append(data['geometry'])\n",
    "            else:\n",
    "                u_pt = Point(G_final.nodes[u]['x'], G_final.nodes[u]['y'])\n",
    "                v_pt = Point(G_final.nodes[v]['x'], G_final.nodes[v]['y'])\n",
    "                route_geoms.append(LineString([u_pt, v_pt]))\n",
    "\n",
    "        if route_geoms:\n",
    "            gdf_route = gpd.GeoDataFrame(geometry=route_geoms, crs=\"EPSG:4326\")\n",
    "            folium.GeoJson(\n",
    "                gdf_route,\n",
    "                name=f\"Route {i}\",\n",
    "                style_function=lambda x: {\n",
    "                    \"color\": \"red\",\n",
    "                    \"weight\": 5,\n",
    "                    \"opacity\": 1,\n",
    "                }\n",
    "            ).add_to(map_final)\n",
    "\n",
    "    folium.LayerControl().add_to(map_final)\n",
    "    return map_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6449b-7f38-4c21-a639-78e3db76c917",
   "metadata": {},
   "source": [
    "## User Friendly Menu Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "976ac8ee-ed7f-4a58-bea8-f1aa36d1e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a list with all the MSOA names so that it can be used as a dropdown\n",
    "all_msoas = sorted(codes_df['MSOA name'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c1024fc-308c-4bca-90a0-1b76eb0bb0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412042d7f29941e19a9ba5c92924946e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Borough:', options=('Westminster', 'Kensington and Chelsea', 'Hammersmith…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Step 1: Dropdowns for borough and MSOA\n",
    "\n",
    "# Loading label\n",
    "loading_label = widgets.Label(value=\"\")  # Initially blank\n",
    "\n",
    "# Borough choices\n",
    "borough_dropdown = widgets.Dropdown(options=boroughs, description='Borough:')\n",
    "\n",
    "# MSOA choices\n",
    "msoa_dropdown = widgets.Dropdown(description='MSOA:')\n",
    "output_map = widgets.Output()\n",
    "\n",
    "# New: Widgets for route parameters\n",
    "k_widget = widgets.IntSlider(value=5, min=1, max=20, step=1, description='Number of routes (k):')\n",
    "m_widget = widgets.IntText(value=1000, description='Minimum route distance (m):')\n",
    "M_widget = widgets.IntText(value=5000, description='Maximum route distance (M):')\n",
    "max_iter_widget = widgets.IntText(value=1000, description='Maximum iterations (max_iter):')\n",
    "beam_width_widget = widgets.IntText(value=3, description='Beam width:')\n",
    "neighbor_sample_widget = widgets.IntText(value=5, description='Neighbor sample:')\n",
    "max_overlap_widget = widgets.IntText(value=5, description='Max overlap:')\n",
    "\n",
    "# Step 2: Update MSOAs when borough is selected\n",
    "def update_msoa_options(*args):\n",
    "    selected_borough = borough_dropdown.value\n",
    "    filtered_msoas = sorted(codes_df[codes_df['ladnm'] == selected_borough]['MSOA name'].unique())\n",
    "    msoa_dropdown.options = filtered_msoas\n",
    "\n",
    "borough_dropdown.observe(update_msoa_options, names='value')\n",
    "\n",
    "# Step 3: Display map when MSOA selected\n",
    "def show_map(button):\n",
    "    with output_map:\n",
    "        clear_output(wait=True)\n",
    "        loading_label.value = \"⏳ Loading map...\"\n",
    "        display(loading_label)\n",
    "        try:\n",
    "            selected_msoa = msoa_dropdown.value\n",
    "            if selected_msoa:\n",
    "                print(f\"Parameters: k={k_widget.value}, m={m_widget.value}, M={M_widget.value}, \"\n",
    "                      f\"max_iterations={max_iter_widget.value}, beam_width={beam_width_widget.value}, \"\n",
    "                      f\"neighbor_sample={neighbor_sample_widget.value}, max_overlap={max_overlap_widget.value}\")\n",
    "                map_obj = routes_visualize(\n",
    "                    selected_msoa,\n",
    "                    k=k_widget.value,\n",
    "                    m=m_widget.value,\n",
    "                    M=M_widget.value,\n",
    "                    max_iterations=max_iter_widget.value,\n",
    "                    beam_width=beam_width_widget.value,\n",
    "                    neighbor_sample=neighbor_sample_widget.value,\n",
    "                    max_overlap=max_overlap_widget.value\n",
    "                )\n",
    "                clear_output(wait=True)\n",
    "                display(map_obj)\n",
    "        except Exception as e:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Error: {e}\")\n",
    "        finally:\n",
    "            loading_label.value = \"\"\n",
    "\n",
    "# Step 4: Button to trigger visualization\n",
    "run_button = widgets.Button(description=\"Show Routes\", button_style='success')\n",
    "run_button.on_click(show_map)\n",
    "\n",
    "# Initial call to populate MSOAs\n",
    "update_msoa_options()\n",
    "\n",
    "# Step 5: Combine everything into a layout, including parameter widgets\n",
    "ui = widgets.VBox([\n",
    "    borough_dropdown,\n",
    "    msoa_dropdown,\n",
    "    k_widget,\n",
    "    m_widget,\n",
    "    M_widget,\n",
    "    max_iter_widget,\n",
    "    beam_width_widget,\n",
    "    neighbor_sample_widget,\n",
    "    max_overlap_widget,\n",
    "    run_button,\n",
    "    output_map\n",
    "])\n",
    "\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
